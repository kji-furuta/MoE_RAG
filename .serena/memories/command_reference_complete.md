# çµ±åˆã‚³ãƒãƒ³ãƒ‰ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

## ç›®æ¬¡
- [ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ](#-ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ)
- [Dockerç’°å¢ƒç®¡ç†](#-dockerç’°å¢ƒç®¡ç†)
- [Webã‚µãƒ¼ãƒãƒ¼ç®¡ç†](#-webã‚µãƒ¼ãƒãƒ¼ç®¡ç†)
- [ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ](#-ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ)
- [RAGæ“ä½œ](#-ragæ“ä½œ)
- [ãƒ¢ãƒ‡ãƒ«è¨“ç·´](#-ãƒ¢ãƒ‡ãƒ«è¨“ç·´)
- [é–‹ç™ºãƒ„ãƒ¼ãƒ«](#ï¸-é–‹ç™ºãƒ„ãƒ¼ãƒ«)
- [ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†](#-ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†)
- [ãƒ‡ãƒãƒƒã‚°ã‚³ãƒãƒ³ãƒ‰](#-ãƒ‡ãƒãƒƒã‚°ã‚³ãƒãƒ³ãƒ‰)
- [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](#-ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°)
- [ä¾¿åˆ©ãªã‚¨ã‚¤ãƒªã‚¢ã‚¹](#-ä¾¿åˆ©ãªã‚¨ã‚¤ãƒªã‚¢ã‚¹)

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ
```bash
# æœ€å°é™ã®èµ·å‹•æ‰‹é †
cd docker && docker-compose up -d
docker exec ai-ft-container bash /workspace/scripts/start_web_interface.sh
# ãƒ–ãƒ©ã‚¦ã‚¶ã§ http://localhost:8050 ã«ã‚¢ã‚¯ã‚»ã‚¹
```

## ğŸ³ Dockerç’°å¢ƒç®¡ç†
```bash
# å®Œå…¨ç’°å¢ƒæ§‹ç¯‰ï¼ˆåˆå›ãƒ»å¤§è¦æ¨¡æ›´æ–°æ™‚ï¼‰
./scripts/docker_build_rag.sh --no-cache

# é€šå¸¸ã®ãƒ“ãƒ«ãƒ‰
./scripts/docker_build_rag.sh

# Docker Composeæ“ä½œ
cd docker
docker-compose up -d --build    # èµ·å‹•
docker-compose down             # åœæ­¢
docker-compose logs -f          # ãƒ­ã‚°ç›£è¦–
docker-compose ps               # çŠ¶æ…‹ç¢ºèª

# ã‚³ãƒ³ãƒ†ãƒŠæ“ä½œ
docker exec -it ai-ft-container bash    # ã‚³ãƒ³ãƒ†ãƒŠã«å…¥ã‚‹
docker restart ai-ft-container          # å†èµ·å‹•
docker stats ai-ft-container            # ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–
```

## ğŸŒ Webã‚µãƒ¼ãƒãƒ¼ç®¡ç†
```bash
# æ¨å¥¨: ã‚¹ã‚¯ãƒªãƒ—ãƒˆçµŒç”±ã§èµ·å‹•
docker exec ai-ft-container bash /workspace/scripts/start_web_interface.sh

# ãƒ‡ãƒãƒƒã‚°: uvicornç›´æ¥èµ·å‹•
docker exec ai-ft-container python -m uvicorn app.main_unified:app --host 0.0.0.0 --port 8050 --reload

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
curl http://localhost:8050/health
curl http://localhost:8050/rag/health

# ãƒ—ãƒ­ã‚»ã‚¹ç¢ºèª
netstat -tlnp | grep 8050
ps aux | grep uvicorn
```

## ğŸ§ª ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
```bash
# åŸºæœ¬ãƒ†ã‚¹ãƒˆ
pytest tests/ -v                                    # å…¨ãƒ†ã‚¹ãƒˆ
pytest tests/test_training.py -v                    # ç‰¹å®šãƒ†ã‚¹ãƒˆ
pytest tests/ -k "test_lora" -v                    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŒ‡å®š

# çµ±åˆãƒ†ã‚¹ãƒˆ
python scripts/test/test_integration.py             # APIçµ±åˆãƒ†ã‚¹ãƒˆ
python scripts/test/test_docker_rag.py             # Docker RAGãƒ†ã‚¹ãƒˆ
python scripts/test/test_memory_optimization.py     # ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ãƒ†ã‚¹ãƒˆ

# ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆ
python scripts/test/test_japanese_simple.py         # æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ç°¡æ˜“ãƒ†ã‚¹ãƒˆ
python scripts/test/simple_lora_tutorial.py         # LoRAãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«

# è¨­å®šãƒ†ã‚¹ãƒˆ
python scripts/test_config_resolution.py           # è¨­å®šè§£æ±ºãƒ†ã‚¹ãƒˆ
python scripts/test_model_path_resolution.py       # ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹è§£æ±ºãƒ†ã‚¹ãƒˆ
```

## ğŸ“š RAGæ“ä½œ
```bash
# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
python scripts/rag/index_documents.py

# RAGã‚¯ã‚¨ãƒªãƒ†ã‚¹ãƒˆ
curl -X POST "http://localhost:8050/rag/query" \
     -H "Content-Type: application/json" \
     -d '{
       "query": "è¨­è¨ˆé€Ÿåº¦80km/hã®é“è·¯ã®æœ€å°æ›²ç·šåŠå¾„ã¯ï¼Ÿ",
       "top_k": 5,
       "search_type": "hybrid"
     }'

# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
curl -X POST "http://localhost:8050/rag/upload" \
     -F "file=@path/to/document.pdf"

# æ¤œç´¢å±¥æ­´å–å¾—
curl "http://localhost:8050/rag/search-history?page=1&limit=10"

# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¸€è¦§
curl "http://localhost:8050/rag/documents"
```

## ğŸ¤– ãƒ¢ãƒ‡ãƒ«è¨“ç·´
```bash
# LoRAãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
python scripts/train_lora.py \
    --model_name "rinna/japanese-gpt2-small" \
    --dataset_path "data/train.jsonl" \
    --output_dir "outputs/lora_model"

# å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«è¨“ç·´
python scripts/train_large_model.py            # æ±ç”¨å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«
python scripts/train_calm3_22b.py              # CALM3 22B
./scripts/train_32b_model.sh                   # 32Bãƒ¢ãƒ‡ãƒ«ç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

# ç¶™ç¶šå­¦ç¿’
./scripts/run_continual_learning.sh            # EWCç¶™ç¶šå­¦ç¿’
python scripts/continual_learning/run_tasks.py # ã‚¿ã‚¹ã‚¯ãƒ™ãƒ¼ã‚¹å­¦ç¿’

# è¨“ç·´çŠ¶æ³ç¢ºèªï¼ˆAPIçµŒç”±ï¼‰
curl "http://localhost:8050/api/training-status/{task_id}"
```

## ğŸ› ï¸ é–‹ç™ºãƒ„ãƒ¼ãƒ«
```bash
# ã‚³ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
black src/ app/ --line-length 88        # Pythonã‚³ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
isort src/ app/ --profile black         # ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ•´ç†

# ãƒªãƒ³ãƒˆ
flake8 src/ app/                        # ã‚³ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯
flake8 --statistics                     # çµ±è¨ˆæƒ…å ±ä»˜ã

# å‹ãƒã‚§ãƒƒã‚¯ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
mypy src/ --ignore-missing-imports

# GPUç›£è¦–
nvidia-smi -l 1                         # 1ç§’ã”ã¨ã«æ›´æ–°
gpustat -i 1                           # ã‚ˆã‚Šè¦‹ã‚„ã™ã„è¡¨ç¤ºï¼ˆè¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼‰

# ãƒ¡ãƒ¢ãƒªç›£è¦–
watch -n 1 free -h                      # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒª
docker stats                            # Dockerã‚³ãƒ³ãƒ†ãƒŠã®ãƒªã‚½ãƒ¼ã‚¹

# ãƒ­ã‚°ç›£è¦–
docker logs -f ai-ft-container --tail 50    # æœ€æ–°50è¡Œã‚’ãƒ•ã‚©ãƒ­ãƒ¼
docker logs ai-ft-container 2>&1 | grep -i error    # ã‚¨ãƒ©ãƒ¼ã®ã¿
tail -f logs/training.log              # ç‰¹å®šãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
```

## ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†
```bash
# ãƒ—ãƒ­ã‚»ã‚¹ç®¡ç†
ps aux | grep python                    # Python ãƒ—ãƒ­ã‚»ã‚¹ç¢ºèª
kill -9 $(ps aux | grep 'uvicorn' | awk '{print $2}')    # uvicornå¼·åˆ¶çµ‚äº†

# ãƒ‡ã‚£ã‚¹ã‚¯ç®¡ç†
df -h                                   # ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨çŠ¶æ³
du -sh /workspace/*                     # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚µã‚¤ã‚º
find /workspace -name "*.pyc" -delete   # ã‚­ãƒ£ãƒƒã‚·ãƒ¥å‰Šé™¤

# Dockerç®¡ç†
docker system df                        # Dockerä½¿ç”¨çŠ¶æ³
docker system prune -a                  # ä¸è¦ãªãƒªã‚½ãƒ¼ã‚¹å‰Šé™¤
docker volume prune                     # ä¸è¦ãªãƒœãƒªãƒ¥ãƒ¼ãƒ å‰Šé™¤

# ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç¢ºèª
curl http://localhost:8050/docs        # FastAPI ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
curl http://localhost:6333              # Qdrant UI
```

## ğŸ ãƒ‡ãƒãƒƒã‚°ã‚³ãƒãƒ³ãƒ‰
```bash
# Pythonã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ç’°å¢ƒ
docker exec -it ai-ft-container python

# ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ
docker exec ai-ft-container python -c "import app.main_unified; print('OK')"

# ç’°å¢ƒå¤‰æ•°ç¢ºèª
docker exec ai-ft-container env | grep -E "HF_|WANDB_|CUDA_"

# ãƒ‘ã‚¹ç¢ºèª
docker exec ai-ft-container python -c "import sys; print('\\n'.join(sys.path))"

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä¸€è¦§
docker exec ai-ft-container pip list | grep -E "torch|transformers|peft"
```

## ğŸš¨ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
```bash
# ãƒ¡ãƒ¢ãƒªä¸è¶³æ™‚
echo 1 > /proc/sys/vm/drop_caches      # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ï¼ˆè¦rootï¼‰
docker restart ai-ft-container          # ã‚³ãƒ³ãƒ†ãƒŠå†èµ·å‹•

# GPU ãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼æ™‚
nvidia-smi --gpu-reset                  # GPU ãƒªã‚»ãƒƒãƒˆï¼ˆè¦æ³¨æ„ï¼‰
docker exec ai-ft-container python -c "import torch; torch.cuda.empty_cache()"

# ãƒãƒ¼ãƒˆç«¶åˆæ™‚
sudo lsof -i :8050                     # ä½¿ç”¨ãƒ—ãƒ­ã‚»ã‚¹ç¢ºèª
sudo fuser -k 8050/tcp                 # ãƒ—ãƒ­ã‚»ã‚¹å¼·åˆ¶çµ‚äº†

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¨ãƒ©ãƒ¼æ™‚
docker exec ai-ft-container pip install -r requirements.txt --force-reinstall
```

## ğŸ“ ä¾¿åˆ©ãªã‚¨ã‚¤ãƒªã‚¢ã‚¹ï¼ˆ.bashrcã«è¿½åŠ ï¼‰
```bash
alias dft='docker exec -it ai-ft-container'
alias dftb='docker exec -it ai-ft-container bash'
alias dftlog='docker logs -f ai-ft-container --tail 50'
alias dftstop='docker-compose -f docker/docker-compose.yml down'
alias dftstart='docker-compose -f docker/docker-compose.yml up -d'
```