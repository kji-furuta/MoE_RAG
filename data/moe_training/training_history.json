{
  "90146e67-a90c-4969-864e-b10a5b8742ae": {
    "task_id": "90146e67-a90c-4969-864e-b10a5b8742ae",
    "status": "completed",
    "progress": 100,
    "current_epoch": 1,
    "current_loss": 0.0,
    "config": {
      "training_type": "demo",
      "base_model": "outputs/ãƒ•ãƒ«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°_20250819_111844",
      "epochs": 3,
      "batch_size": 1,
      "learning_rate": 0.0001,
      "warmup_steps": 100,
      "save_steps": 500,
      "dataset": "demo",
      "experts": [
        "road",
        "regulations"
      ],
      "custom_data_path": null
    },
    "logs": [
      "[2025-08-19T10:01:20.221973] ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã—ãŸ",
      "[2025-08-19T10:01:20.295555] OUT: ===========================================",
      "[2025-08-19T10:01:20.295573] OUT: MoE Training - AI_FT_7 Project",
      "[2025-08-19T10:01:20.295580] OUT: åœŸæœ¨ãƒ»å»ºè¨­åˆ†é‡ç‰¹åŒ–ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°",
      "[2025-08-19T10:01:20.295588] OUT: ===========================================",
      "[2025-08-19T10:01:20.295627] OUT: Dockerç’°å¢ƒã§å®Ÿè¡Œä¸­...",
      "[2025-08-19T10:01:20.295634] OUT: å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰: demo",
      "[2025-08-19T10:01:20.295639] OUT: ã‚¨ãƒãƒƒã‚¯æ•°: 3",
      "[2025-08-19T10:01:20.295642] OUT: ãƒãƒƒãƒã‚µã‚¤ã‚º: 1",
      "[2025-08-19T10:01:20.295658] OUT: ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã—ã¾ã™ï¼ˆå°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ï¼‰...",
      "[2025-08-19T10:01:20.295672] OUT: ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: /workspace/outputs/ãƒ•ãƒ«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°_20250819_111844",
      "[2025-08-19T10:01:27.069516] ERR: INFO:src.moe.moe_training:Loaded 720 samples from ./data/civil_engineering/train",
      "[2025-08-19T10:01:27.070156] ERR: INFO:src.moe.moe_training:Loaded 80 samples from ./data/civil_engineering/val",
      "[2025-08-19T10:01:29.817338] OUT: ============================================================",
      "[2025-08-19T10:01:29.817352] OUT: MoEåœŸæœ¨ãƒ»å»ºè¨­ç‰¹åŒ–ãƒ¢ãƒ‡ãƒ« ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°",
      "[2025-08-19T10:01:29.817357] OUT: ============================================================",
      "[2025-08-19T10:01:29.817361] OUT: âœ“ GPUåˆ©ç”¨å¯èƒ½: 2 devices",
      "[2025-08-19T10:01:29.817365] OUT: Device 0: NVIDIA RTX A5000",
      "[2025-08-19T10:01:29.817367] OUT: Device 1: NVIDIA RTX A5000",
      "[2025-08-19T10:01:29.817373] OUT: ğŸ“ ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰: å°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã§å®Ÿè¡Œã—ã¾ã™",
      "[2025-08-19T10:01:29.817378] OUT: è¨­å®š:",
      "[2025-08-19T10:01:29.817381] OUT: ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆæ•°: 8",
      "[2025-08-19T10:01:29.817384] OUT: ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆ: 2",
      "[2025-08-19T10:01:29.817387] OUT: ãƒãƒƒãƒã‚µã‚¤ã‚º: 1",
      "[2025-08-19T10:01:29.817389] OUT: å­¦ç¿’ç‡: 2e-05",
      "[2025-08-19T10:01:29.817399] OUT: ã‚¨ãƒãƒƒã‚¯æ•°: 1",
      "[2025-08-19T10:01:29.817402] OUT: ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆä¸­...",
      "[2025-08-19T10:01:29.817405] OUT: âœ“ ãƒ¢ãƒ‡ãƒ«ä½œæˆå®Œäº†",
      "[2025-08-19T10:01:29.817408] OUT: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 367,673,440",
      "[2025-08-19T10:01:29.817411] OUT: ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’æº–å‚™ä¸­...",
      "[2025-08-19T10:01:29.817415] OUT: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æº–å‚™ä¸­...",
      "[2025-08-19T10:01:29.817417] OUT: âœ“ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™å®Œäº†",
      "[2025-08-19T10:01:29.817420] OUT: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚µãƒ³ãƒ—ãƒ«: 720",
      "[2025-08-19T10:01:29.817423] OUT: æ¤œè¨¼ã‚µãƒ³ãƒ—ãƒ«: 80",
      "[2025-08-19T10:01:29.817426] OUT: ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚’åˆæœŸåŒ–ä¸­...",
      "[2025-08-19T10:01:29.817430] OUT: ============================================================",
      "[2025-08-19T10:01:29.817432] OUT: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã™...",
      "[2025-08-19T10:01:29.817434] OUT: ============================================================",
      "[2025-08-19T10:01:29.885850] ERR: Epoch 1/1:   0%|          | 0/720 [00:00<?, ?it/s]WARNING:src.moe.moe_architecture:Input IDs exceed vocab size: max=151646, vocab_size=32000. Clamping to safe range.",
      "[2025-08-19T10:01:30.501390] ERR: Epoch 1/1:   0%|          | 0/720 [00:00<?, ?it/s]",
      "[2025-08-19T10:01:30.502270] ERR: Traceback (most recent call last):",
      "[2025-08-19T10:01:30.502420] ERR: File \"/workspace/scripts/moe/run_training.py\", line 243, in main",
      "[2025-08-19T10:01:30.502427] ERR: trainer.train(train_dataset, val_dataset)",
      "[2025-08-19T10:01:30.502430] ERR: File \"/workspace/src/moe/moe_training.py\", line 300, in train",
      "[2025-08-19T10:01:30.502433] ERR: total_loss.backward()",
      "[2025-08-19T10:01:30.502439] ERR: File \"/opt/conda/lib/python3.11/site-packages/torch/_tensor.py\", line 581, in backward",
      "[2025-08-19T10:01:30.502442] ERR: torch.autograd.backward(",
      "[2025-08-19T10:01:30.502462] ERR: File \"/opt/conda/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 347, in backward",
      "[2025-08-19T10:01:30.502465] ERR: _engine_run_backward(",
      "[2025-08-19T10:01:30.502469] ERR: File \"/opt/conda/lib/python3.11/site-packages/torch/autograd/graph.py\", line 825, in _engine_run_backward"
    ],
    "start_time": "2025-08-19T10:01:20.221970",
    "end_time": null,
    "error": null
  },
  "d63ec0db-4f34-48d2-89c1-35b485a819f1": {
    "task_id": "d63ec0db-4f34-48d2-89c1-35b485a819f1",
    "status": "completed",
    "progress": 100,
    "current_epoch": 1,
    "current_loss": 0.0,
    "config": {
      "training_type": "full",
      "base_model": "outputs/ãƒ•ãƒ«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°_20250824_184442",
      "epochs": 3,
      "batch_size": 1,
      "learning_rate": 0.0001,
      "warmup_steps": 100,
      "save_steps": 500,
      "dataset": "demo",
      "experts": [
        "road",
        "regulations"
      ],
      "custom_data_path": null
    },
    "logs": [
      "[2025-08-24T10:23:23.215196] ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã—ãŸ",
      "[2025-08-24T10:23:23.435538] OUT: ===========================================",
      "[2025-08-24T10:23:23.435560] OUT: MoE Training - AI_FT_7 Project",
      "[2025-08-24T10:23:23.435570] OUT: åœŸæœ¨ãƒ»å»ºè¨­åˆ†é‡ç‰¹åŒ–ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°",
      "[2025-08-24T10:23:23.435582] OUT: ===========================================",
      "[2025-08-24T10:23:23.435614] OUT: Dockerç’°å¢ƒã§å®Ÿè¡Œä¸­...",
      "[2025-08-24T10:23:23.435627] OUT: å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰: full",
      "[2025-08-24T10:23:23.435633] OUT: ã‚¨ãƒãƒƒã‚¯æ•°: 3",
      "[2025-08-24T10:23:23.435636] OUT: ãƒãƒƒãƒã‚µã‚¤ã‚º: 1",
      "[2025-08-24T10:23:23.435640] OUT: ãƒ•ãƒ«ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã—ã¾ã™...",
      "[2025-08-24T10:23:23.435643] OUT: ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: /workspace/outputs/ãƒ•ãƒ«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°_20250824_184442",
      "[2025-08-24T10:23:32.146760] OUT: ============================================================",
      "[2025-08-24T10:23:32.146775] OUT: MoEåœŸæœ¨ãƒ»å»ºè¨­ç‰¹åŒ–ãƒ¢ãƒ‡ãƒ« ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°",
      "[2025-08-24T10:23:32.146780] OUT: ============================================================",
      "[2025-08-24T10:23:32.146783] OUT: âœ“ GPUåˆ©ç”¨å¯èƒ½: 2 devices",
      "[2025-08-24T10:23:32.146787] OUT: Device 0: NVIDIA RTX A5000",
      "[2025-08-24T10:23:32.146789] OUT: Device 1: NVIDIA RTX A5000",
      "[2025-08-24T10:23:32.146793] OUT: è¨­å®š:",
      "[2025-08-24T10:23:32.146796] OUT: ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆæ•°: 8",
      "[2025-08-24T10:23:32.146800] OUT: ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆ: 2",
      "[2025-08-24T10:23:32.146803] OUT: ãƒãƒƒãƒã‚µã‚¤ã‚º: 1",
      "[2025-08-24T10:23:32.146805] OUT: å­¦ç¿’ç‡: 2e-05",
      "[2025-08-24T10:23:32.146808] OUT: ã‚¨ãƒãƒƒã‚¯æ•°: 3",
      "[2025-08-24T10:23:32.146811] OUT: ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆä¸­...",
      "[2025-08-24T10:23:32.146814] OUT: ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰ã§ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...",
      "[2025-08-24T10:24:35.987275] ERR: Loading checkpoint shards:   0%|          | 0/14 [00:00<?, ?it/s]\rLoading checkpoint shards:   7%|â–‹         | 1/14 [00:04<00:57,  4.39s/it]\rLoading checkpoint shards:  14%|â–ˆâ–        | 2/14 [00:08<00:52,  4.35s/it]\rLoading checkpoint shards:  21%|â–ˆâ–ˆâ–       | 3/14 [00:14<00:55,  5.06s/it]\rLoading checkpoint shards:  29%|â–ˆâ–ˆâ–Š       | 4/14 [00:19<00:48,  4.84s/it]\rLoading checkpoint shards:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 5/14 [00:23<00:42,  4.73s/it]\rLoading checkpoint shards:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 6/14 [00:28<00:37,  4.71s/it]\rLoading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 7/14 [00:32<00:32,  4.66s/it]\rLoading checkpoint shards:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 8/14 [00:37<00:27,  4.64s/it]\rLoading checkpoint shards:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 9/14 [00:42<00:24,  4.85s/it]\rLoading checkpoint shards:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 10/14 [00:48<00:20,  5.01s/it]\rLoading checkpoint shards:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 11/14 [00:52<00:14,  4.88s/it]\rLoading checkpoint shards:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 12/14 [00:57<00:09,  4.80s/it]\rLoading checkpoint shards:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 13/14 [01:01<00:04,  4.72s/it]\rLoading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [01:03<00:00,  3.88s/it]\rLoading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [01:03<00:00,  4.56s/it]",
      "[2025-08-24T10:24:38.259475] ERR: INFO:src.moe.moe_architecture:Using quantized model with LoRA directly (no MoE wrapper)",
      "[2025-08-24T10:24:38.537337] ERR: INFO:src.moe.moe_training:Loaded 720 samples from ./data/civil_engineering/train",
      "[2025-08-24T10:24:38.539346] ERR: INFO:src.moe.moe_training:Loaded 80 samples from ./data/civil_engineering/val",
      "[2025-08-24T10:24:38.539480] ERR: INFO:src.moe.moe_training:Skipping model device placement (already mapped or quantized)",
      "[2025-08-24T10:24:38.547541] ERR: /workspace/src/moe/moe_training.py:190: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.",
      "[2025-08-24T10:24:38.547549] ERR: self.scaler = torch.cuda.amp.GradScaler() if config.mixed_precision else None",
      "[2025-08-24T10:24:38.558417] OUT: trainable params: 100,663,296 || all params: 32,864,539,648 || trainable%: 0.3063",
      "[2025-08-24T10:24:38.558427] OUT: âœ“ ãƒ¢ãƒ‡ãƒ«ä½œæˆå®Œäº†",
      "[2025-08-24T10:24:38.558432] OUT: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 17,261,728,768",
      "[2025-08-24T10:24:38.558438] OUT: ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’æº–å‚™ä¸­...",
      "[2025-08-24T10:24:38.558442] OUT: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æº–å‚™ä¸­...",
      "[2025-08-24T10:24:38.558444] OUT: âœ“ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™å®Œäº†",
      "[2025-08-24T10:24:38.558447] OUT: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚µãƒ³ãƒ—ãƒ«: 720",
      "[2025-08-24T10:24:38.558450] OUT: æ¤œè¨¼ã‚µãƒ³ãƒ—ãƒ«: 80",
      "[2025-08-24T10:24:38.558453] OUT: ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚’åˆæœŸåŒ–ä¸­...",
      "[2025-08-24T10:24:38.558457] OUT: ============================================================",
      "[2025-08-24T10:24:38.558460] OUT: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã™...",
      "[2025-08-24T10:24:38.558462] OUT: ============================================================",
      "[2025-08-24T10:24:38.602399] ERR: Epoch 1/3:   0%|          | 0/720 [00:00<?, ?it/s]/workspace/src/moe/moe_training.py:269: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.",
      "[2025-08-24T10:24:38.602435] ERR: with torch.cuda.amp.autocast() if self.config.mixed_precision and self.device.type == \"cuda\" else torch.no_grad():",
      "[2025-08-24T10:24:38.602882] ERR: `use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.",
      "[2025-08-24T10:24:38.761145] ERR: /opt/conda/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.",
      "[2025-08-24T10:24:38.761161] ERR: return fn(*args, **kwargs)",
      "[2025-08-24T10:24:40.183648] ERR: Epoch 1/3:   0%|          | 0/720 [00:01<?, ?it/s]"
    ],
    "start_time": "2025-08-24T10:23:23.215193",
    "end_time": null,
    "error": null
  },
  "52484eb0-f1f4-43e1-bef8-7d64dbba6c49": {
    "task_id": "52484eb0-f1f4-43e1-bef8-7d64dbba6c49",
    "status": "completed",
    "progress": 100,
    "current_epoch": 1,
    "current_loss": 0.0,
    "config": {
      "training_type": "demo",
      "base_model": "outputs/ãƒ•ãƒ«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°_20250828_135711",
      "epochs": 3,
      "batch_size": 1,
      "learning_rate": 0.0001,
      "warmup_steps": 100,
      "save_steps": 500,
      "dataset": "demo",
      "experts": [
        "road",
        "regulations"
      ],
      "custom_data_path": null
    },
    "logs": [
      "[2025-08-28T06:24:18.150624] ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã—ãŸ",
      "[2025-08-28T06:24:18.238988] OUT: ===========================================",
      "[2025-08-28T06:24:18.239005] OUT: MoE Training - AI_FT_7 Project",
      "[2025-08-28T06:24:18.239014] OUT: åœŸæœ¨ãƒ»å»ºè¨­åˆ†é‡ç‰¹åŒ–ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°",
      "[2025-08-28T06:24:18.239024] OUT: ===========================================",
      "[2025-08-28T06:24:18.239062] OUT: Dockerç’°å¢ƒã§å®Ÿè¡Œä¸­...",
      "[2025-08-28T06:24:18.239068] OUT: å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰: demo",
      "[2025-08-28T06:24:18.239073] OUT: ã‚¨ãƒãƒƒã‚¯æ•°: 3",
      "[2025-08-28T06:24:18.239076] OUT: ãƒãƒƒãƒã‚µã‚¤ã‚º: 1",
      "[2025-08-28T06:24:18.239092] OUT: ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã—ã¾ã™ï¼ˆå°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ï¼‰...",
      "[2025-08-28T06:24:18.239097] OUT: ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: /workspace/outputs/ãƒ•ãƒ«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°_20250828_135711",
      "[2025-08-28T06:24:25.442839] ERR: INFO:src.moe.moe_training:Loaded 720 samples from ./data/civil_engineering/train",
      "[2025-08-28T06:24:25.444817] ERR: INFO:src.moe.moe_training:Loaded 80 samples from ./data/civil_engineering/val",
      "[2025-08-28T06:24:29.616692] OUT: ============================================================",
      "[2025-08-28T06:24:29.616705] OUT: MoEåœŸæœ¨ãƒ»å»ºè¨­ç‰¹åŒ–ãƒ¢ãƒ‡ãƒ« ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°",
      "[2025-08-28T06:24:29.616710] OUT: ============================================================",
      "[2025-08-28T06:24:29.616713] OUT: âœ“ GPUåˆ©ç”¨å¯èƒ½: 2 devices",
      "[2025-08-28T06:24:29.616717] OUT: Device 0: NVIDIA RTX A5000",
      "[2025-08-28T06:24:29.616720] OUT: Device 1: NVIDIA RTX A5000",
      "[2025-08-28T06:24:29.616725] OUT: ğŸ“ ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰: å°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã§å®Ÿè¡Œã—ã¾ã™",
      "[2025-08-28T06:24:29.616730] OUT: è¨­å®š:",
      "[2025-08-28T06:24:29.616733] OUT: ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆæ•°: 8",
      "[2025-08-28T06:24:29.616735] OUT: ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆ: 2",
      "[2025-08-28T06:24:29.616738] OUT: ãƒãƒƒãƒã‚µã‚¤ã‚º: 1",
      "[2025-08-28T06:24:29.616740] OUT: å­¦ç¿’ç‡: 2e-05",
      "[2025-08-28T06:24:29.616747] OUT: ã‚¨ãƒãƒƒã‚¯æ•°: 1",
      "[2025-08-28T06:24:29.616750] OUT: ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆä¸­...",
      "[2025-08-28T06:24:29.616753] OUT: âœ“ ãƒ¢ãƒ‡ãƒ«ä½œæˆå®Œäº†",
      "[2025-08-28T06:24:29.616755] OUT: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 367,673,440",
      "[2025-08-28T06:24:29.616759] OUT: ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’æº–å‚™ä¸­...",
      "[2025-08-28T06:24:29.616762] OUT: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æº–å‚™ä¸­...",
      "[2025-08-28T06:24:29.616764] OUT: âœ“ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™å®Œäº†",
      "[2025-08-28T06:24:29.616767] OUT: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚µãƒ³ãƒ—ãƒ«: 720",
      "[2025-08-28T06:24:29.616769] OUT: æ¤œè¨¼ã‚µãƒ³ãƒ—ãƒ«: 80",
      "[2025-08-28T06:24:29.616773] OUT: ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚’åˆæœŸåŒ–ä¸­...",
      "[2025-08-28T06:24:29.616777] OUT: ============================================================",
      "[2025-08-28T06:24:29.616779] OUT: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã™...",
      "[2025-08-28T06:24:29.616783] OUT: ============================================================",
      "[2025-08-28T06:24:29.675078] ERR: Epoch 1/1:   0%|          | 0/720 [00:00<?, ?it/s]WARNING:src.moe.moe_architecture:Input IDs exceed vocab size: max=151646, vocab_size=32000. Clamping to safe range.",
      "[2025-08-28T06:24:30.360416] ERR: Epoch 1/1:   0%|          | 0/720 [00:00<?, ?it/s]",
      "[2025-08-28T06:24:30.361734] ERR: Traceback (most recent call last):",
      "[2025-08-28T06:24:30.361844] ERR: File \"/workspace/scripts/moe/run_training.py\", line 243, in main",
      "[2025-08-28T06:24:30.361851] ERR: trainer.train(train_dataset, val_dataset)",
      "[2025-08-28T06:24:30.361854] ERR: File \"/workspace/src/moe/moe_training.py\", line 300, in train",
      "[2025-08-28T06:24:30.361856] ERR: total_loss.backward()",
      "[2025-08-28T06:24:30.361862] ERR: File \"/opt/conda/lib/python3.11/site-packages/torch/_tensor.py\", line 581, in backward",
      "[2025-08-28T06:24:30.361865] ERR: torch.autograd.backward(",
      "[2025-08-28T06:24:30.361882] ERR: File \"/opt/conda/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 347, in backward",
      "[2025-08-28T06:24:30.361885] ERR: _engine_run_backward(",
      "[2025-08-28T06:24:30.361891] ERR: File \"/opt/conda/lib/python3.11/site-packages/torch/autograd/graph.py\", line 825, in _engine_run_backward"
    ],
    "start_time": "2025-08-28T06:24:18.150622",
    "end_time": "2025-08-28T06:24:35.033110",
    "error": null
  },
  "86b10010-cee6-419d-b61d-536df469f752": {
    "task_id": "86b10010-cee6-419d-b61d-536df469f752",
    "status": "completed",
    "progress": 100,
    "current_epoch": 1,
    "current_loss": 0.0,
    "config": {
      "training_type": "full",
      "base_model": "outputs/ãƒ•ãƒ«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°_20250828_135711",
      "epochs": 3,
      "batch_size": 1,
      "learning_rate": 0.0001,
      "warmup_steps": 100,
      "save_steps": 500,
      "dataset": "demo",
      "experts": [
        "road",
        "regulations"
      ],
      "custom_data_path": null
    },
    "logs": [
      "[2025-08-28T06:25:29.682687] ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã—ãŸ",
      "[2025-08-28T06:25:29.754648] OUT: ===========================================",
      "[2025-08-28T06:25:29.754664] OUT: MoE Training - AI_FT_7 Project",
      "[2025-08-28T06:25:29.754671] OUT: åœŸæœ¨ãƒ»å»ºè¨­åˆ†é‡ç‰¹åŒ–ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°",
      "[2025-08-28T06:25:29.754677] OUT: ===========================================",
      "[2025-08-28T06:25:29.754695] OUT: Dockerç’°å¢ƒã§å®Ÿè¡Œä¸­...",
      "[2025-08-28T06:25:29.754705] OUT: å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰: full",
      "[2025-08-28T06:25:29.754708] OUT: ã‚¨ãƒãƒƒã‚¯æ•°: 3",
      "[2025-08-28T06:25:29.754710] OUT: ãƒãƒƒãƒã‚µã‚¤ã‚º: 1",
      "[2025-08-28T06:25:29.754725] OUT: ãƒ•ãƒ«ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã—ã¾ã™...",
      "[2025-08-28T06:25:29.754733] OUT: ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: /workspace/outputs/ãƒ•ãƒ«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°_20250828_135711",
      "[2025-08-28T06:25:39.166892] OUT: ============================================================",
      "[2025-08-28T06:25:39.166905] OUT: MoEåœŸæœ¨ãƒ»å»ºè¨­ç‰¹åŒ–ãƒ¢ãƒ‡ãƒ« ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°",
      "[2025-08-28T06:25:39.166910] OUT: ============================================================",
      "[2025-08-28T06:25:39.166914] OUT: âœ“ GPUåˆ©ç”¨å¯èƒ½: 2 devices",
      "[2025-08-28T06:25:39.166917] OUT: Device 0: NVIDIA RTX A5000",
      "[2025-08-28T06:25:39.166921] OUT: Device 1: NVIDIA RTX A5000",
      "[2025-08-28T06:25:39.166925] OUT: è¨­å®š:",
      "[2025-08-28T06:25:39.166928] OUT: ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆæ•°: 8",
      "[2025-08-28T06:25:39.166931] OUT: ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆ: 2",
      "[2025-08-28T06:25:39.166934] OUT: ãƒãƒƒãƒã‚µã‚¤ã‚º: 1",
      "[2025-08-28T06:25:39.166936] OUT: å­¦ç¿’ç‡: 2e-05",
      "[2025-08-28T06:25:39.166939] OUT: ã‚¨ãƒãƒƒã‚¯æ•°: 3",
      "[2025-08-28T06:25:39.166942] OUT: ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆä¸­...",
      "[2025-08-28T06:25:39.166946] OUT: ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰ã§ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...",
      "[2025-08-28T06:26:41.224415] ERR: Loading checkpoint shards:   0%|          | 0/14 [00:00<?, ?it/s]\rLoading checkpoint shards:   7%|â–‹         | 1/14 [00:04<00:58,  4.50s/it]\rLoading checkpoint shards:  14%|â–ˆâ–        | 2/14 [00:08<00:50,  4.22s/it]\rLoading checkpoint shards:  21%|â–ˆâ–ˆâ–       | 3/14 [00:12<00:45,  4.15s/it]\rLoading checkpoint shards:  29%|â–ˆâ–ˆâ–Š       | 4/14 [00:16<00:41,  4.16s/it]\rLoading checkpoint shards:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 5/14 [00:20<00:37,  4.17s/it]\rLoading checkpoint shards:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 6/14 [00:28<00:41,  5.24s/it]\rLoading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 7/14 [00:32<00:34,  4.88s/it]\rLoading checkpoint shards:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 8/14 [00:36<00:27,  4.65s/it]\rLoading checkpoint shards:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 9/14 [00:40<00:22,  4.48s/it]\rLoading checkpoint shards:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 10/14 [00:44<00:17,  4.41s/it]\rLoading checkpoint shards:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 11/14 [00:49<00:13,  4.36s/it]\rLoading checkpoint shards:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 12/14 [00:53<00:08,  4.30s/it]\rLoading checkpoint shards:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 13/14 [01:00<00:05,  5.13s/it]\rLoading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [01:02<00:00,  4.09s/it]\rLoading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [01:02<00:00,  4.43s/it]",
      "[2025-08-28T06:26:43.142469] ERR: INFO:src.moe.moe_architecture:Using quantized model with LoRA directly (no MoE wrapper)",
      "[2025-08-28T06:26:43.409067] ERR: INFO:src.moe.moe_training:Loaded 720 samples from ./data/civil_engineering/train",
      "[2025-08-28T06:26:43.411647] ERR: INFO:src.moe.moe_training:Loaded 80 samples from ./data/civil_engineering/val",
      "[2025-08-28T06:26:43.411761] ERR: INFO:src.moe.moe_training:Skipping model device placement (already mapped or quantized)",
      "[2025-08-28T06:26:43.419308] ERR: /workspace/src/moe/moe_training.py:190: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.",
      "[2025-08-28T06:26:43.419315] ERR: self.scaler = torch.cuda.amp.GradScaler() if config.mixed_precision else None",
      "[2025-08-28T06:26:43.429750] OUT: trainable params: 100,663,296 || all params: 32,864,539,648 || trainable%: 0.3063",
      "[2025-08-28T06:26:43.429760] OUT: âœ“ ãƒ¢ãƒ‡ãƒ«ä½œæˆå®Œäº†",
      "[2025-08-28T06:26:43.429766] OUT: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 17,261,728,768",
      "[2025-08-28T06:26:43.429770] OUT: ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’æº–å‚™ä¸­...",
      "[2025-08-28T06:26:43.429774] OUT: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æº–å‚™ä¸­...",
      "[2025-08-28T06:26:43.429777] OUT: âœ“ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™å®Œäº†",
      "[2025-08-28T06:26:43.429780] OUT: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚µãƒ³ãƒ—ãƒ«: 720",
      "[2025-08-28T06:26:43.429782] OUT: æ¤œè¨¼ã‚µãƒ³ãƒ—ãƒ«: 80",
      "[2025-08-28T06:26:43.429786] OUT: ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚’åˆæœŸåŒ–ä¸­...",
      "[2025-08-28T06:26:43.429791] OUT: ============================================================",
      "[2025-08-28T06:26:43.429793] OUT: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã™...",
      "[2025-08-28T06:26:43.429796] OUT: ============================================================",
      "[2025-08-28T06:26:43.469553] ERR: Epoch 1/3:   0%|          | 0/720 [00:00<?, ?it/s]/workspace/src/moe/moe_training.py:269: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.",
      "[2025-08-28T06:26:43.469577] ERR: with torch.cuda.amp.autocast() if self.config.mixed_precision and self.device.type == \"cuda\" else torch.no_grad():",
      "[2025-08-28T06:26:43.469917] ERR: `use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.",
      "[2025-08-28T06:26:43.571393] ERR: /opt/conda/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.",
      "[2025-08-28T06:26:43.571407] ERR: return fn(*args, **kwargs)",
      "[2025-08-28T06:26:44.634209] ERR: Epoch 1/3:   0%|          | 0/720 [00:01<?, ?it/s]"
    ],
    "start_time": "2025-08-28T06:25:29.682685",
    "end_time": null,
    "error": null
  },
  "a8cfb3e6-e9af-4f6c-b4f6-d2b98bd8ef04": {
    "task_id": "a8cfb3e6-e9af-4f6c-b4f6-d2b98bd8ef04",
    "status": "completed",
    "progress": 100,
    "current_epoch": 1,
    "current_loss": 0.0,
    "config": {
      "training_type": "full",
      "base_model": "outputs/ãƒ•ãƒ«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°_20250828_135711",
      "epochs": 3,
      "batch_size": 1,
      "learning_rate": 0.0001,
      "warmup_steps": 100,
      "save_steps": 500,
      "dataset": "demo",
      "experts": [
        "road",
        "regulations"
      ],
      "custom_data_path": null
    },
    "logs": [
      "[2025-08-28T06:43:45.338449] ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã—ãŸ",
      "[2025-08-28T06:43:45.391389] OUT: ===========================================",
      "[2025-08-28T06:43:45.391406] OUT: MoE Training - AI_FT_7 Project",
      "[2025-08-28T06:43:45.391417] OUT: åœŸæœ¨ãƒ»å»ºè¨­åˆ†é‡ç‰¹åŒ–ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°",
      "[2025-08-28T06:43:45.391445] OUT: ===========================================",
      "[2025-08-28T06:43:45.391461] OUT: Dockerç’°å¢ƒã§å®Ÿè¡Œä¸­...",
      "[2025-08-28T06:43:45.391467] OUT: å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰: full",
      "[2025-08-28T06:43:45.391470] OUT: ã‚¨ãƒãƒƒã‚¯æ•°: 3",
      "[2025-08-28T06:43:45.391473] OUT: ãƒãƒƒãƒã‚µã‚¤ã‚º: 1",
      "[2025-08-28T06:43:45.391488] OUT: ãƒ•ãƒ«ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã—ã¾ã™...",
      "[2025-08-28T06:43:45.391500] OUT: ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: /workspace/outputs/ãƒ•ãƒ«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°_20250828_135711",
      "[2025-08-28T06:43:51.856912] OUT: ============================================================",
      "[2025-08-28T06:43:51.856924] OUT: MoEåœŸæœ¨ãƒ»å»ºè¨­ç‰¹åŒ–ãƒ¢ãƒ‡ãƒ« ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°",
      "[2025-08-28T06:43:51.856929] OUT: ============================================================",
      "[2025-08-28T06:43:51.856932] OUT: âœ“ GPUåˆ©ç”¨å¯èƒ½: 2 devices",
      "[2025-08-28T06:43:51.856935] OUT: Device 0: NVIDIA RTX A5000",
      "[2025-08-28T06:43:51.856938] OUT: Device 1: NVIDIA RTX A5000",
      "[2025-08-28T06:43:51.856942] OUT: è¨­å®š:",
      "[2025-08-28T06:43:51.856944] OUT: ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆæ•°: 8",
      "[2025-08-28T06:43:51.856948] OUT: ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆ: 2",
      "[2025-08-28T06:43:51.856950] OUT: ãƒãƒƒãƒã‚µã‚¤ã‚º: 1",
      "[2025-08-28T06:43:51.856952] OUT: å­¦ç¿’ç‡: 2e-05",
      "[2025-08-28T06:43:51.856955] OUT: ã‚¨ãƒãƒƒã‚¯æ•°: 3",
      "[2025-08-28T06:43:51.856958] OUT: ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆä¸­...",
      "[2025-08-28T06:43:51.856960] OUT: ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰ã§ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...",
      "[2025-08-28T06:44:55.048794] ERR: Loading checkpoint shards:   0%|          | 0/14 [00:00<?, ?it/s]\rLoading checkpoint shards:   7%|â–‹         | 1/14 [00:04<00:55,  4.30s/it]\rLoading checkpoint shards:  14%|â–ˆâ–        | 2/14 [00:08<00:52,  4.37s/it]\rLoading checkpoint shards:  21%|â–ˆâ–ˆâ–       | 3/14 [00:13<00:48,  4.40s/it]\rLoading checkpoint shards:  29%|â–ˆâ–ˆâ–Š       | 4/14 [00:20<00:55,  5.58s/it]\rLoading checkpoint shards:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 5/14 [00:24<00:46,  5.13s/it]\rLoading checkpoint shards:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 6/14 [00:29<00:39,  4.92s/it]\rLoading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 7/14 [00:33<00:33,  4.72s/it]\rLoading checkpoint shards:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 8/14 [00:38<00:27,  4.60s/it]\rLoading checkpoint shards:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 9/14 [00:42<00:22,  4.53s/it]\rLoading checkpoint shards:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 10/14 [00:46<00:17,  4.37s/it]\rLoading checkpoint shards:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 11/14 [00:53<00:15,  5.16s/it]\rLoading checkpoint shards:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 12/14 [00:57<00:09,  4.82s/it]\rLoading checkpoint shards:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 13/14 [01:01<00:04,  4.58s/it]\rLoading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [01:03<00:00,  3.72s/it]\rLoading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [01:03<00:00,  4.51s/it]",
      "[2025-08-28T06:44:56.790885] ERR: INFO:src.moe.moe_architecture:Using quantized model with LoRA directly (no MoE wrapper)",
      "[2025-08-28T06:44:57.026278] ERR: INFO:src.moe.moe_training:Loaded 720 samples from ./data/civil_engineering/train",
      "[2025-08-28T06:44:57.026914] ERR: INFO:src.moe.moe_training:Loaded 80 samples from ./data/civil_engineering/val",
      "[2025-08-28T06:44:57.027037] ERR: INFO:src.moe.moe_training:Skipping model device placement (already mapped or quantized)",
      "[2025-08-28T06:44:57.034265] ERR: /workspace/src/moe/moe_training.py:190: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.",
      "[2025-08-28T06:44:57.034271] ERR: self.scaler = torch.cuda.amp.GradScaler() if config.mixed_precision else None",
      "[2025-08-28T06:44:57.045134] OUT: trainable params: 100,663,296 || all params: 32,864,539,648 || trainable%: 0.3063",
      "[2025-08-28T06:44:57.045144] OUT: âœ“ ãƒ¢ãƒ‡ãƒ«ä½œæˆå®Œäº†",
      "[2025-08-28T06:44:57.045149] OUT: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 17,261,728,768",
      "[2025-08-28T06:44:57.045154] OUT: ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’æº–å‚™ä¸­...",
      "[2025-08-28T06:44:57.045158] OUT: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æº–å‚™ä¸­...",
      "[2025-08-28T06:44:57.045161] OUT: âœ“ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™å®Œäº†",
      "[2025-08-28T06:44:57.045164] OUT: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚µãƒ³ãƒ—ãƒ«: 720",
      "[2025-08-28T06:44:57.045166] OUT: æ¤œè¨¼ã‚µãƒ³ãƒ—ãƒ«: 80",
      "[2025-08-28T06:44:57.045170] OUT: ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚’åˆæœŸåŒ–ä¸­...",
      "[2025-08-28T06:44:57.045173] OUT: ============================================================",
      "[2025-08-28T06:44:57.045176] OUT: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã™...",
      "[2025-08-28T06:44:57.045178] OUT: ============================================================",
      "[2025-08-28T06:44:57.077094] ERR: Epoch 1/3:   0%|          | 0/720 [00:00<?, ?it/s]/workspace/src/moe/moe_training.py:269: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.",
      "[2025-08-28T06:44:57.077126] ERR: with torch.cuda.amp.autocast() if self.config.mixed_precision and self.device.type == \"cuda\" else torch.no_grad():",
      "[2025-08-28T06:44:57.077442] ERR: `use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.",
      "[2025-08-28T06:44:57.196457] ERR: /opt/conda/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.",
      "[2025-08-28T06:44:57.196472] ERR: return fn(*args, **kwargs)",
      "[2025-08-28T06:44:58.294419] ERR: Epoch 1/3:   0%|          | 0/720 [00:01<?, ?it/s]"
    ],
    "start_time": "2025-08-28T06:43:45.338446",
    "end_time": null,
    "error": null
  },
  "73206a1c-f63f-4b7d-8f85-fc0c89ed48d8": {
    "task_id": "73206a1c-f63f-4b7d-8f85-fc0c89ed48d8",
    "status": "completed",
    "progress": 100,
    "current_epoch": 1,
    "current_loss": 0.0,
    "config": {
      "training_type": "full",
      "base_model": "/workspace/outputs/ãƒ•ãƒ«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°_20250828_164752",
      "epochs": 3,
      "batch_size": 1,
      "learning_rate": 0.0001,
      "warmup_steps": 100,
      "save_steps": 500,
      "dataset": "demo",
      "experts": [
        "road",
        "regulations"
      ],
      "custom_data_path": null
    },
    "logs": [
      "[2025-08-28T09:02:21.300085] ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã—ãŸ",
      "[2025-08-28T09:02:21.468150] OUT: ===========================================",
      "[2025-08-28T09:02:21.468169] OUT: MoE Training - AI_FT_7 Project",
      "[2025-08-28T09:02:21.468189] OUT: åœŸæœ¨ãƒ»å»ºè¨­åˆ†é‡ç‰¹åŒ–ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°",
      "[2025-08-28T09:02:21.468195] OUT: ===========================================",
      "[2025-08-28T09:02:21.468385] OUT: Dockerç’°å¢ƒã§å®Ÿè¡Œä¸­...",
      "[2025-08-28T09:02:21.468417] OUT: å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰: full",
      "[2025-08-28T09:02:21.468430] OUT: ã‚¨ãƒãƒƒã‚¯æ•°: 3",
      "[2025-08-28T09:02:21.468437] OUT: ãƒãƒƒãƒã‚µã‚¤ã‚º: 1",
      "[2025-08-28T09:02:21.468525] OUT: ãƒ•ãƒ«ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã—ã¾ã™...",
      "[2025-08-28T09:02:21.468540] OUT: ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: /workspace/outputs/ãƒ•ãƒ«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°_20250828_164752",
      "[2025-08-28T09:02:28.998500] OUT: ============================================================",
      "[2025-08-28T09:02:28.998521] OUT: MoEåœŸæœ¨ãƒ»å»ºè¨­ç‰¹åŒ–ãƒ¢ãƒ‡ãƒ« ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°",
      "[2025-08-28T09:02:28.998526] OUT: ============================================================",
      "[2025-08-28T09:02:28.998530] OUT: âœ“ GPUåˆ©ç”¨å¯èƒ½: 2 devices",
      "[2025-08-28T09:02:28.998533] OUT: Device 0: NVIDIA RTX A5000",
      "[2025-08-28T09:02:28.998536] OUT: Device 1: NVIDIA RTX A5000",
      "[2025-08-28T09:02:28.998540] OUT: è¨­å®š:",
      "[2025-08-28T09:02:28.998544] OUT: ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆæ•°: 8",
      "[2025-08-28T09:02:28.998548] OUT: ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆ: 2",
      "[2025-08-28T09:02:28.998551] OUT: ãƒãƒƒãƒã‚µã‚¤ã‚º: 1",
      "[2025-08-28T09:02:28.998553] OUT: å­¦ç¿’ç‡: 2e-05",
      "[2025-08-28T09:02:28.998556] OUT: ã‚¨ãƒãƒƒã‚¯æ•°: 3",
      "[2025-08-28T09:02:28.998559] OUT: ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆä¸­...",
      "[2025-08-28T09:02:28.998563] OUT: ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰ã§ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...",
      "[2025-08-28T09:03:30.656237] ERR: Loading checkpoint shards:   0%|          | 0/14 [00:00<?, ?it/s]\rLoading checkpoint shards:   7%|â–‹         | 1/14 [00:04<00:52,  4.04s/it]\rLoading checkpoint shards:  14%|â–ˆâ–        | 2/14 [00:08<00:47,  4.00s/it]\rLoading checkpoint shards:  21%|â–ˆâ–ˆâ–       | 3/14 [00:11<00:43,  3.96s/it]\rLoading checkpoint shards:  29%|â–ˆâ–ˆâ–Š       | 4/14 [00:15<00:39,  3.95s/it]\rLoading checkpoint shards:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 5/14 [00:22<00:45,  5.06s/it]\rLoading checkpoint shards:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 6/14 [00:27<00:38,  4.84s/it]\rLoading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 7/14 [00:31<00:32,  4.59s/it]\rLoading checkpoint shards:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 8/14 [00:35<00:26,  4.43s/it]\rLoading checkpoint shards:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 9/14 [00:39<00:21,  4.32s/it]\rLoading checkpoint shards:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 10/14 [00:43<00:17,  4.33s/it]\rLoading checkpoint shards:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 11/14 [00:48<00:12,  4.32s/it]\rLoading checkpoint shards:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 12/14 [00:55<00:10,  5.26s/it]\rLoading checkpoint shards:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 13/14 [00:59<00:04,  4.95s/it]\rLoading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [01:01<00:00,  4.00s/it]\rLoading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [01:01<00:00,  4.40s/it]",
      "[2025-08-28T09:03:32.657865] ERR: INFO:src.moe.moe_architecture:Using quantized model with LoRA directly (no MoE wrapper)",
      "[2025-08-28T09:03:32.936669] ERR: INFO:src.moe.moe_training:Loaded 720 samples from ./data/civil_engineering/train",
      "[2025-08-28T09:03:32.939150] ERR: INFO:src.moe.moe_training:Loaded 80 samples from ./data/civil_engineering/val",
      "[2025-08-28T09:03:32.939267] ERR: INFO:src.moe.moe_training:Skipping model device placement (already mapped or quantized)",
      "[2025-08-28T09:03:32.947115] ERR: /workspace/src/moe/moe_training.py:190: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.",
      "[2025-08-28T09:03:32.947123] ERR: self.scaler = torch.cuda.amp.GradScaler() if config.mixed_precision else None",
      "[2025-08-28T09:03:32.957186] OUT: trainable params: 100,663,296 || all params: 32,864,539,648 || trainable%: 0.3063",
      "[2025-08-28T09:03:32.957195] OUT: âœ“ ãƒ¢ãƒ‡ãƒ«ä½œæˆå®Œäº†",
      "[2025-08-28T09:03:32.957200] OUT: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 17,261,728,768",
      "[2025-08-28T09:03:32.957205] OUT: ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’æº–å‚™ä¸­...",
      "[2025-08-28T09:03:32.957209] OUT: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æº–å‚™ä¸­...",
      "[2025-08-28T09:03:32.957212] OUT: âœ“ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™å®Œäº†",
      "[2025-08-28T09:03:32.957215] OUT: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚µãƒ³ãƒ—ãƒ«: 720",
      "[2025-08-28T09:03:32.957218] OUT: æ¤œè¨¼ã‚µãƒ³ãƒ—ãƒ«: 80",
      "[2025-08-28T09:03:32.957221] OUT: ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚’åˆæœŸåŒ–ä¸­...",
      "[2025-08-28T09:03:32.957225] OUT: ============================================================",
      "[2025-08-28T09:03:32.957227] OUT: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã™...",
      "[2025-08-28T09:03:32.957230] OUT: ============================================================",
      "[2025-08-28T09:03:32.998462] ERR: Epoch 1/3:   0%|          | 0/720 [00:00<?, ?it/s]/workspace/src/moe/moe_training.py:269: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.",
      "[2025-08-28T09:03:32.998497] ERR: with torch.cuda.amp.autocast() if self.config.mixed_precision and self.device.type == \"cuda\" else torch.no_grad():",
      "[2025-08-28T09:03:32.998815] ERR: `use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.",
      "[2025-08-28T09:03:33.136297] ERR: /opt/conda/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.",
      "[2025-08-28T09:03:33.136312] ERR: return fn(*args, **kwargs)",
      "[2025-08-28T09:03:34.716490] ERR: Epoch 1/3:   0%|          | 0/720 [00:01<?, ?it/s]",
      "[2025-08-28T09:03:34.717470] ERR: Traceback (most recent call last):",
      "[2025-08-28T09:03:34.717610] ERR: File \"/workspace/scripts/moe/run_training.py\", line 243, in main",
      "[2025-08-28T09:03:34.717616] ERR: trainer.train(train_dataset, val_dataset)",
      "[2025-08-28T09:03:34.717620] ERR: File \"/workspace/src/moe/moe_training.py\", line 277, in train",
      "[2025-08-28T09:03:34.717624] ERR: hidden_states = outputs['hidden_states']",
      "[2025-08-28T09:03:34.717627] ERR: ~~~~~~~^^^^^^^^^^^^^^^^^",
      "[2025-08-28T09:03:34.717629] ERR: File \"/opt/conda/lib/python3.11/site-packages/transformers/utils/generic.py\", line 454, in __getitem__",
      "[2025-08-28T09:03:34.717632] ERR: return inner_dict[k]",
      "[2025-08-28T09:03:34.717634] ERR: ~~~~~~~~~~^^^",
      "[2025-08-28T09:03:34.717643] ERR: KeyError: 'hidden_states'",
      "[2025-08-28T09:03:34.741751] OUT: âœ— ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: 'hidden_states'",
      "[2025-08-28T09:03:34.741768] OUT: ============================================================",
      "[2025-08-28T09:03:34.741772] OUT: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°çµ‚äº†",
      "[2025-08-28T09:03:34.741775] OUT: ============================================================",
      "[2025-08-28T09:03:34.741779] OUT: çµæœã®ä¿å­˜å ´æ‰€:",
      "[2025-08-28T09:03:34.741783] OUT: ãƒ¢ãƒ‡ãƒ«: ./outputs/moe_civil",
      "[2025-08-28T09:03:34.741787] OUT: ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ: ./checkpoints/moe_civil",
      "[2025-08-28T09:03:36.155269] OUT: ===========================================",
      "[2025-08-28T09:03:36.155287] OUT: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†",
      "[2025-08-28T09:03:36.155291] OUT: ===========================================",
      "[2025-08-28T09:03:36.156055] ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ"
    ],
    "start_time": "2025-08-28T09:02:21.300083",
    "end_time": null,
    "error": null
  }
}