# Core dependencies
torch>=2.0.0
transformers>=4.35.0
datasets>=2.14.0
accelerate>=0.24.0
bitsandbytes>=0.41.0
peft>=0.6.0

# DeepSpeed for distributed training
deepspeed>=0.11.0

# Tokenizers and model support
sentencepiece>=0.1.99
protobuf>=3.20.0
tokenizers>=0.14.0

# Monitoring and logging
tensorboard>=2.14.0
wandb>=0.15.0
tqdm>=4.66.0

# Utilities
numpy>=1.24.0
pandas>=2.0.0
scikit-learn>=1.3.0
pyyaml>=6.0
jsonlines>=3.1.0

# Japanese language support (optional)
fugashi[unidic-lite]>=1.3.0
mecab-python3>=1.0.6
unidic-lite>=1.0.0

# Memory optimization
nvidia-ml-py>=12.535.0
psutil>=5.9.0

# Additional optimization tools
apex>=0.1  # NVIDIA Apex for mixed precision (optional)
fairscale>=0.4.13  # Facebook FairScale for model parallelism

# Development tools (optional)
ipython>=8.12.0
jupyter>=1.0.0
black>=23.0.0
pylint>=2.17.0
pytest>=7.4.0