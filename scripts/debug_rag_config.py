#!/usr/bin/env python3
"""
RAGè¨­å®šã®èª­ã¿è¾¼ã¿ã‚’ãƒ‡ãƒãƒƒã‚°ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import sys
import os
sys.path.insert(0, '/home/kjifu/MoE_RAG')
os.chdir('/home/kjifu/MoE_RAG')

from src.rag.config.rag_config import load_config
import yaml
from pathlib import Path

def debug_config():
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ç¢ºèª"""
    print("=" * 60)
    print("ğŸ“‹ RAGè¨­å®šãƒ‡ãƒãƒƒã‚°")
    print("=" * 60)
    
    # 1. YAMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥èª­ã¿è¾¼ã¿
    config_path = Path("src/rag/config/rag_config.yaml")
    print(f"\n1. YAMLãƒ•ã‚¡ã‚¤ãƒ«ç›´æ¥èª­ã¿è¾¼ã¿: {config_path}")
    print("-" * 40)
    
    if config_path.exists():
        with open(config_path, 'r', encoding='utf-8') as f:
            yaml_config = yaml.safe_load(f)
            
        llm_config = yaml_config.get('llm', {})
        print(f"provider: {llm_config.get('provider')}")
        print(f"model_name: {llm_config.get('model_name')}")
        print(f"ollama_model: {llm_config.get('ollama_model')}")
        
        if 'ollama' in llm_config:
            print(f"ollama.model: {llm_config['ollama'].get('model')}")
            print(f"ollama.base_url: {llm_config['ollama'].get('base_url')}")
    else:
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config_path}")
    
    # 2. load_config()é–¢æ•°ã§èª­ã¿è¾¼ã¿
    print(f"\n2. load_config()é–¢æ•°ã§ã®èª­ã¿è¾¼ã¿")
    print("-" * 40)
    
    try:
        config = load_config()
        
        if hasattr(config, 'llm'):
            print(f"config.llm.provider: {getattr(config.llm, 'provider', 'ãªã—')}")
            print(f"config.llm.model_name: {getattr(config.llm, 'model_name', 'ãªã—')}")
            print(f"config.llm.ollama_model: {getattr(config.llm, 'ollama_model', 'ãªã—')}")
            
            if hasattr(config.llm, 'ollama'):
                print(f"config.llm.ollama.model: {getattr(config.llm.ollama, 'model', 'ãªã—')}")
                print(f"config.llm.ollama.base_url: {getattr(config.llm.ollama, 'base_url', 'ãªã—')}")
            else:
                print("config.llm.ollama: ãªã—")
        else:
            print("âŒ config.llmãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            
    except Exception as e:
        print(f"âŒ load_config()ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
    
    # 3. QueryEngineã§ã®èª­ã¿è¾¼ã¿ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
    print(f"\n3. QueryEngineã§ã®ãƒ¢ãƒ‡ãƒ«é¸æŠãƒ­ã‚¸ãƒƒã‚¯")
    print("-" * 40)
    
    try:
        config = load_config()
        
        # QueryEngineã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯
        ollama_model = 'llama3.2:3b'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        
        if hasattr(config.llm, 'ollama') and hasattr(config.llm.ollama, 'model'):
            ollama_model = config.llm.ollama.model
            print(f"âœ… config.llm.ollama.modelã‹ã‚‰å–å¾—: {ollama_model}")
        elif hasattr(config.llm, 'ollama_model'):
            ollama_model = config.llm.ollama_model
            print(f"âœ… config.llm.ollama_modelã‹ã‚‰å–å¾—: {ollama_model}")
        elif hasattr(config.llm, 'model_name') and config.llm.model_name.startswith('ollama:'):
            ollama_model = config.llm.model_name[7:]
            print(f"âœ… config.llm.model_nameã‹ã‚‰å–å¾—: {ollama_model}")
        else:
            print(f"âš ï¸ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨: {ollama_model}")
        
        print(f"\næœ€çµ‚çš„ã«ä½¿ç”¨ã•ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«: {ollama_model}")
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    debug_config()