#!/usr/bin/env python3
"""
MoE Integration Test
MoEå®Ÿè£…ã®çµ±åˆãƒ†ã‚¹ãƒˆ
"""

import sys
import os
sys.path.append('/home/kjifu/AI_FT_7')

import torch
import logging
from pathlib import Path

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def test_moe_modules():
    """MoEãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ"""
    print("\n1. MoEãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ")
    print("-" * 40)
    
    try:
        from src.moe import (
            MoEConfig,
            CivilEngineeringExpert,
            MoELayer,
            CivilEngineeringMoEModel,
            ExpertType
        )
        print("âœ“ moe_architecture ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«")
        
        from src.moe import (
            MoETrainingConfig,
            CivilEngineeringDataset,
            MoETrainer
        )
        print("âœ“ moe_training ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«")
        
        from src.moe import (
            DomainData,
            CivilEngineeringDataPreparator
        )
        print("âœ“ data_preparation ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«")
        
        return True
    except ImportError as e:
        print(f"âœ— ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return False


def test_model_creation():
    """ãƒ¢ãƒ‡ãƒ«ä½œæˆãƒ†ã‚¹ãƒˆ"""
    print("\n2. MoEãƒ¢ãƒ‡ãƒ«ä½œæˆãƒ†ã‚¹ãƒˆ")
    print("-" * 40)
    
    try:
        from src.moe.moe_architecture import MoEConfig, CivilEngineeringMoEModel
        
        # å°è¦æ¨¡ãƒ†ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ
        config = MoEConfig(
            hidden_size=256,
            num_experts=8,
            num_experts_per_tok=2,
            dropout=0.1
        )
        
        model = CivilEngineeringMoEModel(config, base_model=None)
        
        print(f"âœ“ ãƒ¢ãƒ‡ãƒ«ä½œæˆæˆåŠŸ")
        print(f"  ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆæ•°: {config.num_experts}")
        print(f"  éš ã‚Œå±¤ã‚µã‚¤ã‚º: {config.hidden_size}")
        print(f"  ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model.parameters()):,}")
        
        return True
    except Exception as e:
        print(f"âœ— ãƒ¢ãƒ‡ãƒ«ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        return False


def test_forward_pass():
    """é †ä¼æ’­ãƒ†ã‚¹ãƒˆ"""
    print("\n3. é †ä¼æ’­ãƒ†ã‚¹ãƒˆ")
    print("-" * 40)
    
    try:
        from src.moe.moe_architecture import MoEConfig, MoELayer
        
        # ãƒ†ã‚¹ãƒˆç”¨ã®å°è¦æ¨¡è¨­å®š
        config = MoEConfig(
            hidden_size=256,
            num_experts=8,
            num_experts_per_tok=2
        )
        
        # MoEãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ä½œæˆ
        moe_layer = MoELayer(config)
        moe_layer.eval()
        
        # ãƒ€ãƒŸãƒ¼å…¥åŠ›
        batch_size, seq_len = 2, 10
        hidden_states = torch.randn(batch_size, seq_len, config.hidden_size)
        
        # é †ä¼æ’­
        with torch.no_grad():
            output, info = moe_layer(hidden_states)
        
        print(f"âœ“ é †ä¼æ’­æˆåŠŸ")
        print(f"  å…¥åŠ›å½¢çŠ¶: {hidden_states.shape}")
        print(f"  å‡ºåŠ›å½¢çŠ¶: {output.shape}")
        print(f"  è£œåŠ©æå¤±: {info['aux_loss'].item():.4f}")
        
        return True
    except Exception as e:
        print(f"âœ— é †ä¼æ’­ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_data_preparation():
    """ãƒ‡ãƒ¼ã‚¿æº–å‚™ãƒ†ã‚¹ãƒˆ"""
    print("\n4. ãƒ‡ãƒ¼ã‚¿æº–å‚™ãƒ†ã‚¹ãƒˆ")
    print("-" * 40)
    
    try:
        from src.moe.data_preparation import CivilEngineeringDataPreparator
        
        # ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ‡ãƒ¼ã‚¿æº–å‚™
        preparator = CivilEngineeringDataPreparator(
            output_dir="./data/civil_engineering_test"
        )
        
        # å°‘é‡ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆ
        preparator.generate_training_data(num_samples_per_domain=5)
        
        print(f"âœ“ ãƒ‡ãƒ¼ã‚¿ç”ŸæˆæˆåŠŸ")
        print(f"  å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ./data/civil_engineering_test")
        
        # ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
        output_dir = Path("./data/civil_engineering_test/train")
        if output_dir.exists():
            files = list(output_dir.glob("*.jsonl"))
            print(f"  ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(files)}")
            for f in files[:3]:  # æœ€åˆã®3ã¤ã‚’è¡¨ç¤º
                print(f"    - {f.name}")
        
        return True
    except Exception as e:
        print(f"âœ— ãƒ‡ãƒ¼ã‚¿æº–å‚™ã‚¨ãƒ©ãƒ¼: {e}")
        return False


def test_expert_routing():
    """ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
    print("\n5. ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ†ã‚¹ãƒˆ")
    print("-" * 40)
    
    try:
        from src.moe.moe_architecture import MoEConfig, TopKRouter, ExpertType
        
        config = MoEConfig(
            hidden_size=256,
            num_experts=8,
            num_experts_per_tok=2,
            domain_specific_routing=True
        )
        
        router = TopKRouter(config)
        router.eval()
        
        # ãƒ†ã‚¹ãƒˆå…¥åŠ›
        batch_size, seq_len = 2, 10
        hidden_states = torch.randn(batch_size, seq_len, config.hidden_size)
        
        # ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
        with torch.no_grad():
            router_logits, expert_indices, expert_weights = router(hidden_states)
        
        print(f"âœ“ ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æˆåŠŸ")
        print(f"  é¸æŠã•ã‚ŒãŸã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆå½¢çŠ¶: {expert_indices.shape}")
        print(f"  ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆé‡ã¿å½¢çŠ¶: {expert_weights.shape}")
        
        # ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆåˆ†å¸ƒã®ç¢ºèª
        unique_experts = torch.unique(expert_indices)
        print(f"  ä½¿ç”¨ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆ: {unique_experts.tolist()}")
        
        return True
    except Exception as e:
        print(f"âœ— ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
        return False


def test_training_loop():
    """ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ«ãƒ¼ãƒ—ãƒ†ã‚¹ãƒˆï¼ˆãƒŸãƒ‹ãƒãƒƒãƒï¼‰"""
    print("\n6. ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ«ãƒ¼ãƒ—ãƒ†ã‚¹ãƒˆ")
    print("-" * 40)
    
    try:
        from src.moe.moe_architecture import MoEConfig, MoELayer
        import torch.nn as nn
        import torch.optim as optim
        
        # å°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«
        config = MoEConfig(
            hidden_size=128,
            num_experts=4,
            num_experts_per_tok=2
        )
        
        moe_layer = MoELayer(config)
        optimizer = optim.Adam(moe_layer.parameters(), lr=1e-4)
        
        # ãƒŸãƒ‹ãƒãƒƒãƒã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
        moe_layer.train()
        for step in range(3):
            # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
            hidden_states = torch.randn(2, 10, config.hidden_size)
            target = torch.randn(2, 10, config.hidden_size)
            
            # Forward
            output, info = moe_layer(hidden_states)
            
            # Loss
            mse_loss = nn.MSELoss()(output, target)
            total_loss = mse_loss + info['aux_loss']
            
            # Backward
            optimizer.zero_grad()
            total_loss.backward()
            optimizer.step()
            
            print(f"  Step {step+1}: Loss={total_loss.item():.4f}, "
                  f"MSE={mse_loss.item():.4f}, Aux={info['aux_loss'].item():.4f}")
        
        print(f"âœ“ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ«ãƒ¼ãƒ—æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âœ— ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
        return False


def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("=" * 60)
    print("MoEå®Ÿè£…çµ±åˆãƒ†ã‚¹ãƒˆ - AI_FT_7ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ")
    print("=" * 60)
    
    # å„ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
    tests = [
        ("MoEãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ", test_moe_modules),
        ("ãƒ¢ãƒ‡ãƒ«ä½œæˆ", test_model_creation),
        ("é †ä¼æ’­", test_forward_pass),
        ("ãƒ‡ãƒ¼ã‚¿æº–å‚™", test_data_preparation),
        ("ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°", test_expert_routing),
        ("ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ«ãƒ¼ãƒ—", test_training_loop)
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            success = test_func()
            results.append((test_name, success))
        except Exception as e:
            print(f"\nâœ— {test_name} ã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
            results.append((test_name, False))
    
    # çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 60)
    print("ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
    print("=" * 60)
    
    passed = sum(1 for _, success in results if success)
    total = len(results)
    
    for test_name, success in results:
        status = "âœ“ PASS" if success else "âœ— FAIL"
        print(f"{status} : {test_name}")
    
    print("-" * 60)
    print(f"çµæœ: {passed}/{total} ãƒ†ã‚¹ãƒˆæˆåŠŸ")
    
    if passed == total:
        print("\nğŸ‰ ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")
        print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("1. ãƒ‡ãƒ¼ã‚¿æº–å‚™: python scripts/moe/prepare_data.py")
        print("2. ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°: python scripts/moe/run_training.py --demo_mode")
    else:
        print("\nâš ï¸ ä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚")
        print("ã‚¨ãƒ©ãƒ¼ã‚’ç¢ºèªã—ã¦ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚")
    
    return passed == total


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
