#!/usr/bin/env python3
"""
RAGã‚·ã‚¹ãƒ†ãƒ ã§ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’äº‹å‰ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import os
import sys
from pathlib import Path
from transformers import AutoTokenizer, AutoModel
from loguru import logger

def preload_embedding_model():
    """åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’äº‹å‰ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    model_name = "intfloat/multilingual-e5-large"
    
    logger.info(f"åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­: {model_name}")
    
    try:
        # ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã¨ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModel.from_pretrained(model_name)
        
        logger.info(f"âœ… ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸ: {model_name}")
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºèª
        cache_dir = Path.home() / ".cache" / "huggingface"
        logger.info(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {cache_dir}")
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
        if cache_dir.exists():
            files = list(cache_dir.rglob("*"))
            logger.info(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(files)}")
        
        return True
        
    except Exception as e:
        logger.error(f"ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return False

def preload_llm_model():
    """LLMãƒ¢ãƒ‡ãƒ«ã‚’äº‹å‰ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    model_name = "cyberagent/DeepSeek-R1-Distill-Qwen-32B-Japanese"
    
    logger.info(f"LLMãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­: {model_name}")
    logger.info("âš ï¸ æ³¨æ„: ã“ã‚Œã¯å¤§ããªãƒ¢ãƒ‡ãƒ«ï¼ˆç´„70GBï¼‰ãªã®ã§ã€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™")
    
    try:
        from transformers import AutoModelForCausalLM
        
        # ãƒ¢ãƒ‡ãƒ«ã®æƒ…å ±ã®ã¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ•ãƒ«ãƒ¢ãƒ‡ãƒ«ã¯å¤§ãã™ãã‚‹ãŸã‚ï¼‰
        logger.info("ãƒ¢ãƒ‡ãƒ«è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
        from huggingface_hub import snapshot_download
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆallow_patterns ã§å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ï¼‰
        snapshot_download(
            repo_id=model_name,
            cache_dir=Path.home() / ".cache" / "huggingface",
            allow_patterns=["*.json", "*.txt", "tokenizer*", "*.model"],  # è¨­å®šã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®ã¿
            local_dir_use_symlinks=False
        )
        
        logger.info(f"âœ… ãƒ¢ãƒ‡ãƒ«è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸ: {model_name}")
        logger.info("ğŸ’¡ ãƒ•ãƒ«ãƒ¢ãƒ‡ãƒ«ã¯èµ·å‹•æ™‚ã«å¿…è¦ã«å¿œã˜ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™")
        
        return True
        
    except Exception as e:
        logger.error(f"ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return False

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    logger.info("RAGãƒ¢ãƒ‡ãƒ«ã®äº‹å‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’é–‹å§‹ã—ã¾ã™...")
    
    # åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    embedding_success = preload_embedding_model()
    
    # LLMãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    llm_success = preload_llm_model()
    
    if embedding_success and llm_success:
        logger.info("âœ… ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸ")
        logger.info("æ¬¡å›ã‹ã‚‰ã¯èµ·å‹•æ™‚ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™")
    else:
        logger.error("âŒ ä¸€éƒ¨ã®ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ")
        sys.exit(1)

if __name__ == "__main__":
    main()