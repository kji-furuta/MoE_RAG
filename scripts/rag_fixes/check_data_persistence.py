#!/usr/bin/env python3
"""
RAGã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒ¼ã‚¿æ°¸ç¶šæ€§ã‚’æ¤œè¨¼ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import os
import sys
import json
import sqlite3
from pathlib import Path
from datetime import datetime

sys.path.insert(0, "/workspace" if os.path.exists("/workspace") else ".")

def check_qdrant_persistence():
    """Qdrantã®ãƒ‡ãƒ¼ã‚¿æ°¸ç¶šæ€§ã‚’ç¢ºèª"""
    print("\n1. Qdrantãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ç¢ºèª")
    print("-" * 40)
    
    # Qdrantãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ã®ç¢ºèª
    qdrant_paths = [
        Path("data/qdrant"),
        Path("qdrant_data")
    ]
    
    for qdrant_path in qdrant_paths:
        if qdrant_path.exists():
            print(f"\nğŸ“ {qdrant_path}:")
            
            # SQLiteãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
            sqlite_files = list(qdrant_path.glob("**/*.sqlite"))
            for sqlite_file in sqlite_files:
                size = sqlite_file.stat().st_size
                print(f"  ğŸ“„ {sqlite_file.name}: {size:,} bytes")
                
                if size < 20000:  # 20KBæœªæº€ã¯ç©ºã¨ã¿ãªã™
                    print(f"    âš ï¸  ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå°ã•ã™ãã¾ã™ï¼ˆãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰")
                    
                    # SQLiteã®å†…å®¹ã‚’ç¢ºèª
                    try:
                        conn = sqlite3.connect(sqlite_file)
                        cursor = conn.cursor()
                        
                        # ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã‚’å–å¾—
                        cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
                        tables = cursor.fetchall()
                        
                        print(f"    ãƒ†ãƒ¼ãƒ–ãƒ«æ•°: {len(tables)}")
                        
                        for table in tables:
                            cursor.execute(f"SELECT COUNT(*) FROM {table[0]}")
                            count = cursor.fetchone()[0]
                            print(f"      - {table[0]}: {count} ãƒ¬ã‚³ãƒ¼ãƒ‰")
                        
                        conn.close()
                    except Exception as e:
                        print(f"    âŒ SQLiteèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            
            # meta.jsonã®ç¢ºèª
            meta_file = qdrant_path / "meta.json"
            if meta_file.exists():
                with open(meta_file, 'r') as f:
                    meta = json.load(f)
                    
                print(f"\n  ğŸ“‹ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿:")
                for collection, config in meta.get('collections', {}).items():
                    print(f"    ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³: {collection}")
                    if 'vectors' in config:
                        print(f"      æ¬¡å…ƒ: {config['vectors']['size']}")
                        print(f"      è·é›¢: {config['vectors']['distance']}")

def check_metadata_manager():
    """MetadataManagerã®ãƒ‡ãƒ¼ã‚¿æ°¸ç¶šæ€§ã‚’ç¢ºèª"""
    print("\n2. MetadataManagerã®ç¢ºèª")
    print("-" * 40)
    
    metadata_paths = [
        Path("metadata/metadata.db"),
        Path("data/metadata/metadata.db")
    ]
    
    found = False
    for db_path in metadata_paths:
        if db_path.exists():
            found = True
            size = db_path.stat().st_size
            print(f"  ğŸ“„ {db_path}: {size:,} bytes")
            
            try:
                conn = sqlite3.connect(db_path)
                cursor = conn.cursor()
                
                # document_metadataãƒ†ãƒ¼ãƒ–ãƒ«ã®ç¢ºèª
                cursor.execute("""
                    SELECT COUNT(*) FROM sqlite_master 
                    WHERE type='table' AND name='document_metadata'
                """)
                
                if cursor.fetchone()[0] > 0:
                    cursor.execute("SELECT COUNT(*) FROM document_metadata")
                    doc_count = cursor.fetchone()[0]
                    print(f"    æ–‡æ›¸æ•°: {doc_count}")
                    
                    if doc_count > 0:
                        cursor.execute("""
                            SELECT id, title, file_path, created_at 
                            FROM document_metadata 
                            LIMIT 5
                        """)
                        docs = cursor.fetchall()
                        print(f"    æœ€è¿‘ã®æ–‡æ›¸:")
                        for doc in docs:
                            print(f"      - {doc[1][:30]}... ({doc[2]})")
                else:
                    print(f"    âš ï¸  document_metadataãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
                
                conn.close()
            except Exception as e:
                print(f"    âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    if not found:
        print(f"  âš ï¸  MetadataManagerã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

def check_vector_store_data():
    """ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèª"""
    print("\n3. ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®ãƒ‡ãƒ¼ã‚¿ç¢ºèª")
    print("-" * 40)
    
    try:
        from src.rag.indexing.vector_store import QdrantVectorStore
        
        vector_store = QdrantVectorStore(
            collection_name="road_design_docs",
            embedding_dim=1024,
            path="./data/qdrant"
        )
        
        # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±ã®å–å¾—
        info = vector_store.get_collection_info()
        
        print(f"  ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³çŠ¶æ…‹:")
        print(f"    ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {info.get('status', 'unknown')}")
        print(f"    ãƒ™ã‚¯ãƒˆãƒ«æ•°: {info.get('vectors_count', 0)}")
        print(f"    ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ¸ˆã¿: {info.get('indexed_vectors_count', 0)}")
        
        vectors_count = info.get('vectors_count', 0)
        
        if vectors_count == 0:
            print(f"    âš ï¸  ãƒ‡ãƒ¼ã‚¿ãŒä¿å­˜ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        else:
            print(f"    âœ… {vectors_count}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ãŒä¿å­˜ã•ã‚Œã¦ã„ã¾ã™")
            
            # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã‚’è©¦ã¿ã‚‹
            try:
                # ãƒ€ãƒŸãƒ¼ã®ã‚¯ã‚¨ãƒªã§æ¤œç´¢
                import numpy as np
                dummy_embedding = np.random.randn(1024).astype(np.float32)
                results = vector_store.search(
                    query_embedding=dummy_embedding,
                    top_k=min(3, vectors_count)
                )
                
                print(f"\n    ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿:")
                for i, result in enumerate(results, 1):
                    text_preview = result.text[:50] if result.text else "N/A"
                    print(f"      {i}. {text_preview}...")
                    print(f"         ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {list(result.metadata.keys())}")
            except Exception as e:
                print(f"    âš ï¸  ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—: {e}")
                
    except Exception as e:
        print(f"  âŒ ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®ç¢ºèªã«å¤±æ•—: {e}")

def check_backup_system():
    """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ ã®ç¢ºèª"""
    print("\n4. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ ã®ç¢ºèª")
    print("-" * 40)
    
    backup_dir = Path("backups")
    
    if backup_dir.exists():
        backups = list(backup_dir.iterdir())
        print(f"  ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ•°: {len(backups)}")
        
        if backups:
            print(f"  æœ€è¿‘ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—:")
            for backup in sorted(backups, key=lambda x: x.stat().st_mtime, reverse=True)[:5]:
                mtime = datetime.fromtimestamp(backup.stat().st_mtime)
                size = sum(f.stat().st_size for f in backup.rglob('*') if f.is_file())
                print(f"    - {backup.name}: {size:,} bytes ({mtime.strftime('%Y-%m-%d %H:%M')})")
        else:
            print(f"  âš ï¸  ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
    else:
        print(f"  âš ï¸  ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“")

def generate_report():
    """æ°¸ç¶šæ€§ã®å•é¡Œã¨æ¨å¥¨äº‹é …ã‚’ã¾ã¨ã‚ã‚‹"""
    print("\n" + "=" * 60)
    print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿æ°¸ç¶šæ€§ãƒ¬ãƒãƒ¼ãƒˆ")
    print("=" * 60)
    
    issues = []
    recommendations = []
    
    # Qdrantãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
    qdrant_path = Path("data/qdrant/collection/road_design_docs/storage.sqlite")
    if qdrant_path.exists():
        size = qdrant_path.stat().st_size
        if size < 20000:
            issues.append("Qdrant SQLiteãƒ•ã‚¡ã‚¤ãƒ«ãŒã»ã¼ç©ºï¼ˆãƒ‡ãƒ¼ã‚¿æœªä¿å­˜ï¼‰")
            recommendations.append("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å†ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒå¿…è¦")
    else:
        issues.append("Qdrant SQLiteãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„")
        recommendations.append("Qdrantã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ–ãŒå¿…è¦")
    
    # MetadataManagerã®ç¢ºèª
    metadata_db = Path("metadata/metadata.db")
    if not metadata_db.exists():
        issues.append("MetadataManagerã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒå­˜åœ¨ã—ãªã„")
        recommendations.append("MetadataManagerã®åˆæœŸåŒ–ãŒå¿…è¦")
    
    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®ç¢ºèª
    backup_dir = Path("backups")
    if not backup_dir.exists() or not list(backup_dir.iterdir()):
        issues.append("ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒå­˜åœ¨ã—ãªã„")
        recommendations.append("å®šæœŸãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…ãŒå¿…è¦")
    
    # ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›
    if issues:
        print("\nâŒ ç™ºè¦‹ã•ã‚ŒãŸå•é¡Œ:")
        for i, issue in enumerate(issues, 1):
            print(f"  {i}. {issue}")
        
        print("\nğŸ’¡ æ¨å¥¨äº‹é …:")
        for i, rec in enumerate(recommendations, 1):
            print(f"  {i}. {rec}")
        
        print("\nğŸ”§ ä¿®æ­£ã‚¹ã‚¯ãƒªãƒ—ãƒˆ:")
        print("  python scripts/rag_fixes/fix_data_persistence.py")
    else:
        print("\nâœ… ãƒ‡ãƒ¼ã‚¿æ°¸ç¶šæ€§ã«å•é¡Œã¯ã‚ã‚Šã¾ã›ã‚“")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 60)
    print("ğŸ” RAGã‚·ã‚¹ãƒ†ãƒ  ãƒ‡ãƒ¼ã‚¿æ°¸ç¶šæ€§ãƒã‚§ãƒƒã‚¯")
    print("=" * 60)
    
    check_qdrant_persistence()
    check_metadata_manager()
    check_vector_store_data()
    check_backup_system()
    generate_report()

if __name__ == "__main__":
    main()
