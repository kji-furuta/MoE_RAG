#!/usr/bin/env python3
"""
æ—¢å­˜ã®RAGãƒ‡ãƒ¼ã‚¿ã‚’æ–°ã—ã„æ°¸ç¶šåŒ–ã‚·ã‚¹ãƒ†ãƒ ã«ç§»è¡Œã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import os
import sys
import json
from pathlib import Path
from datetime import datetime
import sqlite3
import logging

sys.path.insert(0, "/workspace" if os.path.exists("/workspace") else ".")

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DataMigration:
    """æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®ç§»è¡Œã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        # æ°¸ç¶šåŒ–ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã®åˆæœŸåŒ–
        from scripts.rag_fixes.integrate_persistence import PersistentRAGAdapter
        self.adapter = PersistentRAGAdapter()
        
        self.migration_stats = {
            'documents_found': 0,
            'documents_migrated': 0,
            'documents_failed': 0,
            'vectors_found': 0,
            'vectors_migrated': 0,
            'start_time': None,
            'end_time': None
        }
    
    def migrate_from_qdrant(self):
        """æ—¢å­˜ã®Qdrantãƒ‡ãƒ¼ã‚¿ã‚’ç§»è¡Œ"""
        print("\n1. Qdrantã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ç§»è¡Œ")
        print("-" * 40)
        
        try:
            from src.rag.indexing.vector_store import QdrantVectorStore
            import numpy as np
            
            # æ—¢å­˜ã®Qdrantã‚¹ãƒˆã‚¢
            old_store = QdrantVectorStore(
                collection_name="road_design_docs",
                embedding_dim=1024,
                path="./data/qdrant"
            )
            
            # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±ã®å–å¾—
            info = old_store.get_collection_info()
            vectors_count = info.get('vectors_count', 0)
            
            print(f"  æ—¢å­˜ãƒ™ã‚¯ãƒˆãƒ«æ•°: {vectors_count}")
            self.migration_stats['vectors_found'] = vectors_count
            
            if vectors_count == 0:
                print("  â„¹ï¸  ç§»è¡Œã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                return 0
            
            # ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆç°¡æ˜“çš„ãªæ–¹æ³•ï¼‰
            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«APIã‚’ä½¿ç”¨ã™ã¹ã
            dummy_query = np.random.randn(1024).astype(np.float32)
            
            batch_size = 100
            migrated = 0
            
            for offset in range(0, min(vectors_count, 1000), batch_size):
                try:
                    results = old_store.search(
                        query_embedding=dummy_query,
                        top_k=batch_size,
                        score_threshold=0.0  # ã™ã¹ã¦å–å¾—
                    )
                    
                    for result in results:
                        try:
                            # æ–°ã—ã„ã‚·ã‚¹ãƒ†ãƒ ã«è¿½åŠ 
                            doc_id = self.adapter.add_document(
                                text=result.text,
                                title=result.metadata.get('title', f'Migrated Doc {migrated+1}'),
                                metadata=result.metadata
                            )
                            
                            migrated += 1
                            self.migration_stats['documents_migrated'] += 1
                            
                            if migrated % 10 == 0:
                                print(f"    ç§»è¡Œæ¸ˆã¿: {migrated}ä»¶")
                                
                        except Exception as e:
                            logger.warning(f"Failed to migrate document: {e}")
                            self.migration_stats['documents_failed'] += 1
                            
                except Exception as e:
                    logger.warning(f"Failed to fetch batch at offset {offset}: {e}")
                    break
            
            print(f"  âœ… {migrated}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç§»è¡Œã—ã¾ã—ãŸ")
            return migrated
            
        except Exception as e:
            logger.error(f"Qdrant migration failed: {e}")
            return 0
    
    def migrate_from_metadata_db(self):
        """MetadataManagerã®ãƒ‡ãƒ¼ã‚¿ã‚’ç§»è¡Œ"""
        print("\n2. MetadataManagerã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ç§»è¡Œ")
        print("-" * 40)
        
        metadata_paths = [
            Path("metadata/metadata.db"),
            Path("data/metadata/metadata.db")
        ]
        
        for db_path in metadata_paths:
            if db_path.exists():
                print(f"  ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: {db_path}")
                
                try:
                    conn = sqlite3.connect(db_path)
                    cursor = conn.cursor()
                    
                    # æ–‡æ›¸ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
                    cursor.execute("""
                        SELECT id, title, filename, file_path, category, subcategory,
                               version, created_at, custom_fields
                        FROM document_metadata
                        WHERE status = 'ACTIVE' OR status = 'active'
                    """)
                    
                    documents = cursor.fetchall()
                    print(f"  æ–‡æ›¸æ•°: {len(documents)}")
                    
                    migrated = 0
                    for doc in documents:
                        try:
                            # ã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ãƒ‘ãƒ¼ã‚¹
                            custom_fields = json.loads(doc[8]) if doc[8] else {}
                            
                            metadata = {
                                'original_id': doc[0],
                                'filename': doc[2],
                                'file_path': doc[3],
                                'category': doc[4],
                                'subcategory': doc[5],
                                'version': doc[6],
                                'created_at': doc[7],
                                **custom_fields
                            }
                            
                            # ãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å–å¾—ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€å¿…è¦ãŒã‚ã‚‹å ´åˆï¼‰
                            text = f"Metadata entry for {doc[1]}"  # å®Ÿéš›ã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿
                            
                            # æ–°ã—ã„ã‚·ã‚¹ãƒ†ãƒ ã«è¿½åŠ 
                            doc_id = self.adapter.add_document(
                                text=text,
                                title=doc[1],
                                metadata=metadata,
                                file_path=doc[3]
                            )
                            
                            migrated += 1
                            
                        except Exception as e:
                            logger.warning(f"Failed to migrate metadata {doc[0]}: {e}")
                    
                    conn.close()
                    
                    print(f"  âœ… {migrated}ä»¶ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ç§»è¡Œã—ã¾ã—ãŸ")
                    self.migration_stats['documents_migrated'] += migrated
                    
                    return migrated
                    
                except Exception as e:
                    logger.error(f"Metadata migration failed: {e}")
                    
        print("  â„¹ï¸  MetadataManagerã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return 0
    
    def migrate_documents_from_directory(self, directory: str = "data/rag_documents"):
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ç§»è¡Œ"""
        print(f"\n3. ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ã®æ–‡æ›¸ç§»è¡Œ: {directory}")
        print("-" * 40)
        
        doc_dir = Path(directory)
        if not doc_dir.exists():
            print(f"  â„¹ï¸  ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {directory}")
            return 0
        
        # PDFã¨ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        documents = list(doc_dir.glob("**/*.pdf")) + \
                   list(doc_dir.glob("**/*.txt")) + \
                   list(doc_dir.glob("**/*.md"))
        
        print(f"  æ–‡æ›¸ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(documents)}")
        self.migration_stats['documents_found'] = len(documents)
        
        migrated = 0
        for doc_path in documents:
            try:
                # ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
                if doc_path.suffix == '.pdf':
                    # PDFã®å‡¦ç†ï¼ˆå®Ÿè£…ãŒå¿…è¦ï¼‰
                    print(f"    â­ï¸  PDFãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚¹ã‚­ãƒƒãƒ—: {doc_path.name}")
                    continue
                else:
                    with open(doc_path, 'r', encoding='utf-8') as f:
                        text = f.read()
                
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ§‹ç¯‰
                metadata = {
                    'source': 'file',
                    'file_type': doc_path.suffix,
                    'file_size': doc_path.stat().st_size,
                    'modified': datetime.fromtimestamp(doc_path.stat().st_mtime).isoformat()
                }
                
                # ã‚«ãƒ†ã‚´ãƒªã®æŽ¨å®šï¼ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã‹ã‚‰ï¼‰
                if doc_path.parent != doc_dir:
                    metadata['category'] = doc_path.parent.name
                
                # æ–°ã—ã„ã‚·ã‚¹ãƒ†ãƒ ã«è¿½åŠ 
                doc_id = self.adapter.add_document(
                    text=text,
                    title=doc_path.stem,
                    metadata=metadata,
                    file_path=str(doc_path)
                )
                
                migrated += 1
                print(f"    âœ… {doc_path.name}")
                
            except Exception as e:
                logger.warning(f"Failed to migrate {doc_path}: {e}")
                self.migration_stats['documents_failed'] += 1
        
        self.migration_stats['documents_migrated'] += migrated
        print(f"  âœ… {migrated}ä»¶ã®æ–‡æ›¸ã‚’ç§»è¡Œã—ã¾ã—ãŸ")
        return migrated
    
    def create_migration_report(self):
        """ç§»è¡Œãƒ¬ãƒãƒ¼ãƒˆã®ä½œæˆ"""
        report_path = Path("data/rag_persistent/migration_report.json")
        report_path.parent.mkdir(parents=True, exist_ok=True)
        
        self.migration_stats['end_time'] = datetime.now().isoformat()
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(self.migration_stats, f, ensure_ascii=False, indent=2)
        
        print(f"\nðŸ“„ ç§»è¡Œãƒ¬ãƒãƒ¼ãƒˆ: {report_path}")
        return report_path
    
    def run_full_migration(self):
        """å®Œå…¨ãªç§»è¡Œã‚’å®Ÿè¡Œ"""
        print("=" * 60)
        print("ðŸ”„ æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®ç§»è¡Œ")
        print("=" * 60)
        
        self.migration_stats['start_time'] = datetime.now().isoformat()
        
        # å„ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã®ç§»è¡Œ
        qdrant_count = self.migrate_from_qdrant()
        metadata_count = self.migrate_from_metadata_db()
        file_count = self.migrate_documents_from_directory()
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®ä½œæˆ
        print("\n4. ç§»è¡Œå¾Œã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ")
        print("-" * 40)
        
        total_migrated = qdrant_count + metadata_count + file_count
        if total_migrated > 0:
            backup_name = f"migration_{datetime.now().strftime('%Y%m%d_%H%M')}_{total_migrated}docs"
            backup_path = self.adapter.create_backup(backup_name)
            print(f"  âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {backup_path}")
        
        # ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
        self.create_migration_report()
        
        # ã‚µãƒžãƒªãƒ¼è¡¨ç¤º
        print("\n" + "=" * 60)
        print("ðŸ“Š ç§»è¡Œã‚µãƒžãƒªãƒ¼")
        print("=" * 60)
        print(f"  æ–‡æ›¸ç™ºè¦‹æ•°: {self.migration_stats['documents_found']}")
        print(f"  ç§»è¡ŒæˆåŠŸ: {self.migration_stats['documents_migrated']}")
        print(f"  ç§»è¡Œå¤±æ•—: {self.migration_stats['documents_failed']}")
        print(f"  ãƒ™ã‚¯ãƒˆãƒ«ç™ºè¦‹æ•°: {self.migration_stats['vectors_found']}")
        print(f"  ãƒ™ã‚¯ãƒˆãƒ«ç§»è¡Œæ•°: {self.migration_stats['vectors_migrated']}")
        
        if self.migration_stats['documents_migrated'] > 0:
            print("\nâœ… ãƒ‡ãƒ¼ã‚¿ç§»è¡ŒãŒå®Œäº†ã—ã¾ã—ãŸ")
        else:
            print("\nâš ï¸  ç§»è¡Œã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        
        return total_migrated


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    migration = DataMigration()
    
    # ç¢ºèªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    print("\nâš ï¸  æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’æ–°ã—ã„æ°¸ç¶šåŒ–ã‚·ã‚¹ãƒ†ãƒ ã«ç§»è¡Œã—ã¾ã™")
    print("ç§»è¡Œå…ƒ:")
    print("  â€¢ Qdrant (data/qdrant/)")
    print("  â€¢ MetadataManager (metadata/metadata.db)")
    print("  â€¢ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (data/rag_documents/)")
    print("")
    
    response = input("ç¶šè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/n): ")
    if response.lower() != 'y':
        print("ç§»è¡Œã‚’ä¸­æ­¢ã—ã¾ã—ãŸ")
        return
    
    # ç§»è¡Œå®Ÿè¡Œ
    migrated_count = migration.run_full_migration()
    
    return migrated_count > 0


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
