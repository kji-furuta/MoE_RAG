#!/usr/bin/env python3
"""
è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…
å®šæœŸçš„ãªãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’ç®¡ç†
"""

import os
import sys
import time
import json
import schedule
import threading
from pathlib import Path
from datetime import datetime, timedelta
import logging

sys.path.insert(0, "/workspace" if os.path.exists("/workspace") else ".")

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class AutoBackupManager:
    """è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼"""
    
    def __init__(self, config_path: str = "./config/backup_config.json"):
        self.config_path = Path(config_path)
        self.config = self._load_config()
        
        # æ°¸ç¶šåŒ–ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã®åˆæœŸåŒ–
        from scripts.rag_fixes.integrate_persistence import PersistentRAGAdapter
        self.adapter = PersistentRAGAdapter()
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—çµ±è¨ˆ
        self.stats = {
            'total_backups': 0,
            'successful_backups': 0,
            'failed_backups': 0,
            'last_backup': None,
            'total_size_bytes': 0
        }
        
        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã®è¨­å®š
        self._setup_schedule()
        
        logger.info(f"AutoBackupManager initialized with config: {config_path}")
    
    def _load_config(self) -> dict:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿"""
        default_config = {
            'enabled': True,
            'backup_schedule': {
                'hourly': False,
                'daily': True,
                'weekly': True,
                'time': "03:00"  # æ¯æ—¥3æ™‚
            },
            'retention': {
                'keep_daily': 7,    # 7æ—¥åˆ†ã®æ—¥æ¬¡ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
                'keep_weekly': 4,   # 4é€±åˆ†ã®é€±æ¬¡ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
                'keep_monthly': 3   # 3ãƒ¶æœˆåˆ†ã®æœˆæ¬¡ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
            },
            'incremental': {
                'enabled': True,
                'threshold': 100  # 100æ–‡æ›¸ã”ã¨ã«å¢—åˆ†ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
            },
            'compression': {
                'enabled': True,
                'format': 'gzip'
            },
            'notification': {
                'enabled': False,
                'webhook_url': None
            }
        }
        
        if self.config_path.exists():
            with open(self.config_path, 'r') as f:
                config = json.load(f)
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã¨ãƒãƒ¼ã‚¸
                for key in default_config:
                    if key not in config:
                        config[key] = default_config[key]
                return config
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä¿å­˜
            self.config_path.parent.mkdir(parents=True, exist_ok=True)
            with open(self.config_path, 'w') as f:
                json.dump(default_config, f, indent=2)
            return default_config
    
    def _setup_schedule(self):
        """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®è¨­å®š"""
        if not self.config['enabled']:
            logger.info("Auto backup is disabled")
            return
        
        schedule_config = self.config['backup_schedule']
        
        # æ—¥æ¬¡ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
        if schedule_config.get('daily'):
            schedule.every().day.at(schedule_config['time']).do(
                self._run_backup, backup_type='daily'
            )
            logger.info(f"Daily backup scheduled at {schedule_config['time']}")
        
        # é€±æ¬¡ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆæ—¥æ›œæ—¥ï¼‰
        if schedule_config.get('weekly'):
            schedule.every().sunday.at(schedule_config['time']).do(
                self._run_backup, backup_type='weekly'
            )
            logger.info(f"Weekly backup scheduled on Sunday at {schedule_config['time']}")
        
        # æ™‚é–“ã”ã¨ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
        if schedule_config.get('hourly'):
            schedule.every().hour.do(
                self._run_backup, backup_type='hourly'
            )
            logger.info("Hourly backup scheduled")
    
    def _run_backup(self, backup_type: str = 'manual'):
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®å®Ÿè¡Œ"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            backup_name = f"{backup_type}_{timestamp}"
            
            logger.info(f"Starting {backup_type} backup: {backup_name}")
            
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Ÿè¡Œ
            backup_path = self.adapter.create_backup(backup_name)
            
            # çµ±è¨ˆæ›´æ–°
            self.stats['total_backups'] += 1
            self.stats['successful_backups'] += 1
            self.stats['last_backup'] = datetime.now().isoformat()
            
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚µã‚¤ã‚ºã®è¨ˆç®—
            backup_dir = Path(backup_path)
            if backup_dir.exists():
                size = sum(f.stat().st_size for f in backup_dir.rglob('*') if f.is_file())
                self.stats['total_size_bytes'] += size
                
                # åœ§ç¸®ãŒæœ‰åŠ¹ãªå ´åˆ
                if self.config['compression']['enabled']:
                    self._compress_backup(backup_dir)
            
            logger.info(f"Backup completed successfully: {backup_name}")
            
            # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            self._cleanup_old_backups()
            
            # é€šçŸ¥
            if self.config['notification']['enabled']:
                self._send_notification(f"Backup completed: {backup_name}", 'success')
            
            return True
            
        except Exception as e:
            self.stats['failed_backups'] += 1
            logger.error(f"Backup failed: {e}")
            
            if self.config['notification']['enabled']:
                self._send_notification(f"Backup failed: {e}", 'error')
            
            return False
    
    def _compress_backup(self, backup_dir: Path):
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®åœ§ç¸®"""
        import gzip
        import tarfile
        
        try:
            format = self.config['compression']['format']
            
            if format == 'gzip':
                # tar.gzãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
                archive_path = backup_dir.with_suffix('.tar.gz')
                
                with tarfile.open(archive_path, 'w:gz') as tar:
                    tar.add(backup_dir, arcname=backup_dir.name)
                
                # å…ƒã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤
                import shutil
                shutil.rmtree(backup_dir)
                
                logger.info(f"Backup compressed: {archive_path}")
                
        except Exception as e:
            logger.warning(f"Failed to compress backup: {e}")
    
    def _cleanup_old_backups(self):
        """å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        retention = self.config['retention']
        
        try:
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å–å¾—
            backup_base = Path("data/rag_persistent/backups")
            if not backup_base.exists():
                return
            
            now = datetime.now()
            
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†é¡
            daily_backups = []
            weekly_backups = []
            monthly_backups = []
            
            for backup in backup_base.iterdir():
                if backup.is_dir() or backup.suffix in ['.gz', '.tar']:
                    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®æ—¥æ™‚ã‚’å–å¾—
                    mtime = datetime.fromtimestamp(backup.stat().st_mtime)
                    age_days = (now - mtime).days
                    
                    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¿ã‚¤ãƒ—ã®åˆ¤å®š
                    if 'daily' in backup.name:
                        daily_backups.append((backup, mtime, age_days))
                    elif 'weekly' in backup.name:
                        weekly_backups.append((backup, mtime, age_days))
                    elif 'monthly' in backup.name:
                        monthly_backups.append((backup, mtime, age_days))
            
            # å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®å‰Šé™¤
            self._remove_old_backups(daily_backups, retention['keep_daily'], 'daily')
            self._remove_old_backups(weekly_backups, retention['keep_weekly'] * 7, 'weekly')
            self._remove_old_backups(monthly_backups, retention['keep_monthly'] * 30, 'monthly')
            
        except Exception as e:
            logger.warning(f"Cleanup failed: {e}")
    
    def _remove_old_backups(self, backups: list, keep_days: int, backup_type: str):
        """æŒ‡å®šã•ã‚ŒãŸæœŸé–“ã‚ˆã‚Šå¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å‰Šé™¤"""
        import shutil
        
        for backup_path, mtime, age_days in backups:
            if age_days > keep_days:
                try:
                    if backup_path.is_dir():
                        shutil.rmtree(backup_path)
                    else:
                        backup_path.unlink()
                    
                    logger.info(f"Removed old {backup_type} backup: {backup_path.name} ({age_days} days old)")
                    
                except Exception as e:
                    logger.warning(f"Failed to remove {backup_path}: {e}")
    
    def _send_notification(self, message: str, level: str = 'info'):
        """é€šçŸ¥ã®é€ä¿¡"""
        if not self.config['notification']['enabled']:
            return
        
        webhook_url = self.config['notification'].get('webhook_url')
        if not webhook_url:
            return
        
        try:
            import requests
            
            payload = {
                'text': f"[RAG Backup {level.upper()}] {message}",
                'timestamp': datetime.now().isoformat()
            }
            
            response = requests.post(webhook_url, json=payload, timeout=5)
            
            if response.status_code != 200:
                logger.warning(f"Notification failed: {response.status_code}")
                
        except Exception as e:
            logger.warning(f"Failed to send notification: {e}")
    
    def start_scheduler(self):
        """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’é–‹å§‹"""
        def run_schedule():
            while True:
                schedule.run_pending()
                time.sleep(60)  # 1åˆ†ã”ã¨ã«ãƒã‚§ãƒƒã‚¯
        
        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œ
        scheduler_thread = threading.Thread(target=run_schedule, daemon=True)
        scheduler_thread.start()
        
        logger.info("Backup scheduler started")
    
    def get_status(self) -> dict:
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ ã®çŠ¶æ…‹ã‚’å–å¾—"""
        return {
            'enabled': self.config['enabled'],
            'stats': self.stats,
            'next_backup': self._get_next_backup_time(),
            'config': self.config
        }
    
    def _get_next_backup_time(self) -> str:
        """æ¬¡ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ™‚åˆ»ã‚’å–å¾—"""
        jobs = schedule.get_jobs()
        if jobs:
            # æ¬¡ã®å®Ÿè¡Œæ™‚åˆ»ã‚’è¨ˆç®—ï¼ˆç°¡ç•¥ç‰ˆï¼‰
            return self.config['backup_schedule']['time']
        return "Not scheduled"
    
    def perform_manual_backup(self) -> bool:
        """æ‰‹å‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®å®Ÿè¡Œ"""
        return self._run_backup('manual')
    
    def restore_latest_backup(self) -> bool:
        """æœ€æ–°ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒ"""
        backup_base = Path("data/rag_persistent/backups")
        
        if not backup_base.exists():
            logger.error("No backup directory found")
            return False
        
        # æœ€æ–°ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’æ¤œç´¢
        backups = sorted(
            backup_base.iterdir(),
            key=lambda x: x.stat().st_mtime,
            reverse=True
        )
        
        if not backups:
            logger.error("No backups found")
            return False
        
        latest_backup = backups[0]
        logger.info(f"Restoring from: {latest_backup.name}")
        
        return self.adapter.restore_backup(latest_backup.name)


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 60)
    print("ğŸ”§ è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—")
    print("=" * 60)
    
    # 1. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®åˆæœŸåŒ–
    print("\n1. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®åˆæœŸåŒ–")
    manager = AutoBackupManager()
    print("  âœ… ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–å®Œäº†")
    
    # 2. ç¾åœ¨ã®çŠ¶æ…‹è¡¨ç¤º
    print("\n2. ç¾åœ¨ã®çŠ¶æ…‹")
    status = manager.get_status()
    print(f"  æœ‰åŠ¹: {status['enabled']}")
    print(f"  ç·ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ•°: {status['stats']['total_backups']}")
    print(f"  æˆåŠŸ: {status['stats']['successful_backups']}")
    print(f"  å¤±æ•—: {status['stats']['failed_backups']}")
    print(f"  æœ€çµ‚ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {status['stats']['last_backup'] or 'ãªã—'}")
    print(f"  æ¬¡å›ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {status['next_backup']}")
    
    # 3. ãƒ†ã‚¹ãƒˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®å®Ÿè¡Œ
    print("\n3. ãƒ†ã‚¹ãƒˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®å®Ÿè¡Œ")
    success = manager.perform_manual_backup()
    if success:
        print("  âœ… ãƒ†ã‚¹ãƒˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æˆåŠŸ")
    else:
        print("  âŒ ãƒ†ã‚¹ãƒˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¤±æ•—")
    
    # 4. ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã®èµ·å‹•
    print("\n4. ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã®èµ·å‹•")
    manager.start_scheduler()
    print("  âœ… ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼èµ·å‹•å®Œäº†")
    
    print("\nâœ… è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†")
    print("\nãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«:")
    config = manager.config['backup_schedule']
    if config['daily']:
        print(f"  æ—¥æ¬¡: æ¯æ—¥ {config['time']}")
    if config['weekly']:
        print(f"  é€±æ¬¡: æ¯é€±æ—¥æ›œæ—¥ {config['time']}")
    if config['hourly']:
        print(f"  æ™‚é–“: æ¯æ™‚")
    
    print("\nä¿æŒæœŸé–“:")
    retention = manager.config['retention']
    print(f"  æ—¥æ¬¡ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {retention['keep_daily']}æ—¥")
    print(f"  é€±æ¬¡ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {retention['keep_weekly']}é€±")
    print(f"  æœˆæ¬¡ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {retention['keep_monthly']}ãƒ¶æœˆ")
    
    return manager


if __name__ == "__main__":
    manager = main()
    
    # ãƒ‡ãƒ¼ãƒ¢ãƒ³ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã™ã‚‹å ´åˆ
    if '--daemon' in sys.argv:
        print("\nğŸ”„ ãƒ‡ãƒ¼ãƒ¢ãƒ³ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œä¸­... (Ctrl+Cã§çµ‚äº†)")
        try:
            while True:
                time.sleep(60)
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ ã‚’çµ‚äº†ã—ã¾ã™")
