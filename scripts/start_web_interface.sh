#!/bin/bash

# AI_FT_3 çµ±åˆWebã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹èµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
# ç¶™ç¶šå­¦ç¿’ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’å«ã‚€å…¨æ©Ÿèƒ½ã‚’èµ·å‹•

echo "ðŸš€ AI_FT_3 çµ±åˆWebã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’èµ·å‹•ä¸­..."

# Ollamaã‚µãƒ¼ãƒ“ã‚¹ã‚’èµ·å‹•ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
if command -v ollama &> /dev/null; then
    echo "ðŸ¤– Ollamaã‚µãƒ¼ãƒ“ã‚¹ã‚’èµ·å‹•ä¸­..."
    nohup ollama serve > /dev/null 2>&1 &
    sleep 3
    echo "âœ… Ollamaã‚µãƒ¼ãƒ“ã‚¹ã‚’èµ·å‹•ã—ã¾ã—ãŸ (port 11434)"
    
    # Ollamaãƒ¢ãƒ‡ãƒ«ã®ç¢ºèªã¨è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    echo "ðŸ“¦ Ollamaãƒ¢ãƒ‡ãƒ«ã‚’ç¢ºèªä¸­..."
    if ! ollama list | grep -q "llama3.2:3b"; then
        echo "ðŸ“¥ llama3.2:3bãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­..."
        ollama pull llama3.2:3b
        echo "âœ… ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸ"
    else
        echo "âœ… llama3.2:3bãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨å¯èƒ½ã§ã™"
    fi
fi

# ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨­å®š
cd /workspace

# ãƒ‘ãƒ¼ãƒŸãƒƒã‚·ãƒ§ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯ãƒ»ä¿®æ­£
echo "ðŸ” ãƒ‘ãƒ¼ãƒŸãƒƒã‚·ãƒ§ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯ä¸­..."
if [ -f /workspace/scripts/setup_permissions.sh ]; then
    /workspace/scripts/setup_permissions.sh --check
    if [ $? -ne 0 ]; then
        echo "ðŸ”§ ãƒ‘ãƒ¼ãƒŸãƒƒã‚·ãƒ§ãƒ³ã‚’ä¿®æ­£ä¸­..."
        if [ "$EUID" -eq 0 ]; then
            /workspace/scripts/setup_permissions.sh
        else
            sudo /workspace/scripts/setup_permissions.sh 2>/dev/null || /workspace/scripts/setup_permissions.sh
        fi
    fi
else
    echo "âš ï¸ ãƒ‘ãƒ¼ãƒŸãƒƒã‚·ãƒ§ãƒ³è¨­å®šã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬çš„ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    mkdir -p /workspace/outputs
    mkdir -p /workspace/data/continual_learning
    mkdir -p /workspace/logs
    mkdir -p /workspace/temp_uploads
fi

# ç¶™ç¶šå­¦ç¿’ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
echo "ðŸ“‹ ç¶™ç¶šå­¦ç¿’ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ä¸­..."

# ç¶™ç¶šå­¦ç¿’ç”¨ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
cat > /workspace/config/continual_learning_config.yaml << EOF
# ç¶™ç¶šå­¦ç¿’ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ è¨­å®š
continual_learning:
  enabled: true
  base_models:
    - cyberagent/calm3-22b-chat
    - cyberagent/DeepSeek-R1-Distill-Qwen-32B-Japanese
    - Qwen/Qwen2.5-14B-Instruct
    - Qwen/Qwen2.5-32B-Instruct
  
  ewc_settings:
    default_lambda: 5000
    fisher_computation_batches: 100
    use_efficient_storage: true
  
  training_settings:
    default_epochs: 3
    default_learning_rate: 2e-5
    default_batch_size: 4
    max_sequence_length: 512

# ãƒ¢ãƒ‡ãƒ«ç®¡ç†è¨­å®š
model_management:
  auto_detect_finetuned: true
  include_base_models: true
  cache_enabled: true
EOF

echo "âœ… ç¶™ç¶šå­¦ç¿’ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®è¨­å®šã‚’å®Œäº†"

# Webã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•
echo "ðŸŒ çµ±åˆWebã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ä¸­..."
echo "ðŸ“Š åˆ©ç”¨å¯èƒ½ãªæ©Ÿèƒ½:"
echo "  - ãƒ¡ã‚¤ãƒ³ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰: http://localhost:8050/"
echo "  - ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°: http://localhost:8050/finetune"
echo "  - ç¶™ç¶šå­¦ç¿’ç®¡ç†: http://localhost:8050/continual"
echo "  - RAGã‚·ã‚¹ãƒ†ãƒ : http://localhost:8050/rag"
echo "  - ãƒ¢ãƒ‡ãƒ«ç®¡ç†: http://localhost:8050/models"

# çµ±åˆWebã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•
exec python3 -m uvicorn app.main_unified:app --host 0.0.0.0 --port 8050 --reload
