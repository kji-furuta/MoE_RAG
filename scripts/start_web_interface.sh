#!/bin/bash

# AI_FT_3 çµ±åˆWebã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹èµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
# ç¶™ç¶šå­¦ç¿’ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’å«ã‚€å…¨æ©Ÿèƒ½ã‚’èµ·å‹•

echo "ðŸš€ AI_FT_3 çµ±åˆWebã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’èµ·å‹•ä¸­..."

# ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨­å®š
cd /workspace

# å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
mkdir -p /workspace/outputs
mkdir -p /workspace/data/continual_learning
mkdir -p /workspace/logs

# ç¶™ç¶šå­¦ç¿’ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
echo "ðŸ“‹ ç¶™ç¶šå­¦ç¿’ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ä¸­..."

# ç¶™ç¶šå­¦ç¿’ç”¨ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
cat > /workspace/config/continual_learning_config.yaml << EOF
# ç¶™ç¶šå­¦ç¿’ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ è¨­å®š
continual_learning:
  enabled: true
  base_models:
    - cyberagent/calm3-22b-chat
    - cyberagent/DeepSeek-R1-Distill-Qwen-32B-Japanese
    - Qwen/Qwen2.5-14B-Instruct
    - Qwen/Qwen2.5-32B-Instruct
  
  ewc_settings:
    default_lambda: 5000
    fisher_computation_batches: 100
    use_efficient_storage: true
  
  training_settings:
    default_epochs: 3
    default_learning_rate: 2e-5
    default_batch_size: 4
    max_sequence_length: 512

# ãƒ¢ãƒ‡ãƒ«ç®¡ç†è¨­å®š
model_management:
  auto_detect_finetuned: true
  include_base_models: true
  cache_enabled: true
EOF

echo "âœ… ç¶™ç¶šå­¦ç¿’ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®è¨­å®šã‚’å®Œäº†"

# Webã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•
echo "ðŸŒ çµ±åˆWebã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ä¸­..."
echo "ðŸ“Š åˆ©ç”¨å¯èƒ½ãªæ©Ÿèƒ½:"
echo "  - ãƒ¡ã‚¤ãƒ³ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰: http://localhost:8050/"
echo "  - ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°: http://localhost:8050/finetune"
echo "  - ç¶™ç¶šå­¦ç¿’ç®¡ç†: http://localhost:8050/continual"
echo "  - RAGã‚·ã‚¹ãƒ†ãƒ : http://localhost:8050/rag"
echo "  - ãƒ¢ãƒ‡ãƒ«ç®¡ç†: http://localhost:8050/models"

# çµ±åˆWebã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•
exec python3 -m uvicorn app.main_unified:app --host 0.0.0.0 --port 8050 --reload