#!/bin/bash

# AI_FT_3 çµ±åˆWebã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹èµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆDockerå¯¾å¿œç‰ˆï¼‰
# ç¶™ç¶šå­¦ç¿’ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’å«ã‚€å…¨æ©Ÿèƒ½ã‚’èµ·å‹•

echo "ğŸš€ AI_FT_3 çµ±åˆWebã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’èµ·å‹•ä¸­..."
echo "ğŸ³ Dockerç’°å¢ƒã‚’æ¤œå‡º..."

# Dockerç’°å¢ƒã®æ¤œå‡º
if [ -f /.dockerenv ] || [ -n "$DOCKER_CONTAINER" ]; then
    echo "âœ… Dockerç’°å¢ƒã§å®Ÿè¡Œä¸­"
    export DOCKER_CONTAINER=true
else
    echo "â„¹ï¸ é€šå¸¸ç’°å¢ƒã§å®Ÿè¡Œä¸­"
fi

# Ollamaã‚µãƒ¼ãƒ“ã‚¹ã‚’èµ·å‹•ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
if command -v ollama &> /dev/null; then
    echo "ğŸ¤– Ollamaã‚µãƒ¼ãƒ“ã‚¹ã‚’èµ·å‹•ä¸­..."
    # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§Ollamaã‚’èµ·å‹•
    nohup ollama serve > /tmp/ollama.log 2>&1 &
    OLLAMA_PID=$!
    sleep 3
    
    # OllamaãŒèµ·å‹•ã—ãŸã‹ç¢ºèª
    if ps -p $OLLAMA_PID > /dev/null; then
        echo "âœ… Ollamaã‚µãƒ¼ãƒ“ã‚¹ã‚’èµ·å‹•ã—ã¾ã—ãŸ (PID: $OLLAMA_PID, port 11434)"
    else
        echo "âš ï¸ Ollamaã‚µãƒ¼ãƒ“ã‚¹ã®èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸ"
    fi
    
    # Ollamaãƒ¢ãƒ‡ãƒ«ã®ç¢ºèª
    echo "ğŸ“¦ Ollamaãƒ¢ãƒ‡ãƒ«ã‚’ç¢ºèªä¸­..."
    if ollama list 2>/dev/null | grep -q "llama3.2:3b"; then
        echo "âœ… llama3.2:3bãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨å¯èƒ½ã§ã™"
    else
        echo "ğŸ“¥ llama3.2:3bãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­..."
        ollama pull llama3.2:3b 2>/dev/null || echo "âš ï¸ ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’ã‚¹ã‚­ãƒƒãƒ—"
    fi
else
    echo "â„¹ï¸ OllamaãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“"
fi

# ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨­å®š
cd /workspace || cd /home/kjifu/MoE_RAG || exit 1

# å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
echo "ğŸ“ å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆä¸­..."
mkdir -p outputs data/continual_learning logs temp_uploads
mkdir -p data/uploaded config

# ãƒ‘ãƒ¼ãƒŸãƒƒã‚·ãƒ§ãƒ³ã®ä¿®æ­£ï¼ˆDockerç’°å¢ƒã§ã¯å¿…è¦ãªå ´åˆã®ã¿ï¼‰
if [ -f scripts/setup_permissions.sh ]; then
    echo "ğŸ” ãƒ‘ãƒ¼ãƒŸãƒƒã‚·ãƒ§ãƒ³ã‚’è¨­å®šä¸­..."
    if [ "$EUID" -eq 0 ]; then
        # ãƒ«ãƒ¼ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å ´åˆ
        bash scripts/setup_permissions.sh 2>/dev/null || true
    else
        # ä¸€èˆ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å ´åˆ
        bash scripts/setup_permissions.sh --check 2>/dev/null || true
    fi
fi

# ç¶™ç¶šå­¦ç¿’ç”¨ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆï¼ˆå­˜åœ¨ã—ãªã„å ´åˆï¼‰
if [ ! -f config/continual_learning_config.yaml ]; then
    echo "ğŸ“‹ ç¶™ç¶šå­¦ç¿’ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®è¨­å®šã‚’ä½œæˆä¸­..."
    cat > config/continual_learning_config.yaml << 'EOF'
# ç¶™ç¶šå­¦ç¿’ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ è¨­å®š
continual_learning:
  enabled: true
  base_models:
    - cyberagent/calm3-22b-chat
    - Qwen/Qwen2.5-14B-Instruct
  
  ewc_settings:
    default_lambda: 5000
    fisher_computation_batches: 100
    use_efficient_storage: true
  
  training_settings:
    default_epochs: 3
    default_learning_rate: 2e-5
    default_batch_size: 4
    max_sequence_length: 512

model_management:
  auto_detect_finetuned: true
  include_base_models: true
  cache_enabled: true
EOF
    echo "âœ… ç¶™ç¶šå­¦ç¿’ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®è¨­å®šã‚’ä½œæˆã—ã¾ã—ãŸ"
fi

# Pythonãƒ‘ã‚¹ã‚’è¨­å®š
export PYTHONPATH=/workspace:$PYTHONPATH

# ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–è¨­å®šï¼ˆDockerç’°å¢ƒç”¨ï¼‰
export PYTORCH_CUDA_ALLOC_CONF="max_split_size_mb:512"
export OMP_NUM_THREADS=4
export MKL_NUM_THREADS=4

echo ""
echo "ğŸŒ çµ±åˆWebã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ä¸­..."
echo "ğŸ“Š åˆ©ç”¨å¯èƒ½ãªæ©Ÿèƒ½:"
echo "  - ãƒ¡ã‚¤ãƒ³ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰: http://localhost:8050/"
echo "  - API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: http://localhost:8050/docs"
echo "  - ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°: http://localhost:8050/static/moe_training.html"
echo "  - ç¶™ç¶šå­¦ç¿’ç®¡ç†: http://localhost:8050/static/continual_learning/index.html"
echo "  - RAGã‚·ã‚¹ãƒ†ãƒ : http://localhost:8050/static/moe_rag_ui.html"
echo ""

# æ—¢å­˜ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’ç¢ºèª
if lsof -i:8050 > /dev/null 2>&1; then
    echo "âš ï¸ ãƒãƒ¼ãƒˆ8050ã¯æ—¢ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚æ—¢å­˜ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’çµ‚äº†ã—ã¾ã™..."
    kill $(lsof -t -i:8050) 2>/dev/null || true
    sleep 2
fi

# Dockerç’°å¢ƒç”¨ã®main_unifiedã‚’ä½¿ç”¨
if [ -f app/main_unified_docker.py ]; then
    echo "ğŸ³ Dockerå¯¾å¿œç‰ˆã®ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã—ã¾ã™..."
    exec python3 -m uvicorn app.main_unified_docker:app \
        --host 0.0.0.0 \
        --port 8050 \
        --workers 1 \
        --loop asyncio \
        --log-level info
else
    echo "ğŸ“¦ é€šå¸¸ç‰ˆã®ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã—ã¾ã™..."
    exec python3 -m uvicorn app.main_unified:app \
        --host 0.0.0.0 \
        --port 8050 \
        --reload \
        --log-level info
fi
