#!/usr/bin/env python3
"""
å®Œå…¨ãªMoEãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®çµ±åˆãƒ†ã‚¹ãƒˆ
1. æ•™å¸«ãƒ‡ãƒ¼ã‚¿ä½œæˆ
2. LoRAãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
3. MoEãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆLoRAã‹ã‚‰ã®å¤‰æ›ï¼‰
4. GGUFå¤‰æ›
5. RAGã‚·ã‚¹ãƒ†ãƒ ã§ã®ä½¿ç”¨
"""

import sys
import os
import json
import time
import subprocess
from pathlib import Path
from typing import Dict, List
import logging

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class MoEPipelineTest:
    """MoEãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å…¨ä½“ã®ãƒ†ã‚¹ãƒˆ"""
    
    def __init__(self, workspace_dir: str = "/workspace"):
        self.workspace_dir = Path(workspace_dir)
        self.data_dir = self.workspace_dir / "data" / "training"
        self.outputs_dir = self.workspace_dir / "outputs"
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.data_dir.mkdir(parents=True, exist_ok=True)
        self.outputs_dir.mkdir(parents=True, exist_ok=True)
    
    def step1_create_training_data(self) -> bool:
        """ã‚¹ãƒ†ãƒƒãƒ—1: æ•™å¸«ãƒ‡ãƒ¼ã‚¿ä½œæˆ"""
        logger.info("=" * 60)
        logger.info("ã‚¹ãƒ†ãƒƒãƒ—1: æ•™å¸«ãƒ‡ãƒ¼ã‚¿ä½œæˆ")
        logger.info("=" * 60)
        
        # å°‚é–€åˆ†é‡ã”ã¨ã®æ•™å¸«ãƒ‡ãƒ¼ã‚¿
        datasets = {
            "road_design": [
                {"prompt": "è¨­è¨ˆé€Ÿåº¦120km/hã®æœ€å°æ›²ç·šåŠå¾„ã¯ï¼Ÿ", "response": "710m"},
                {"prompt": "è¨­è¨ˆé€Ÿåº¦100km/hã®æœ€å°æ›²ç·šåŠå¾„ã¯ï¼Ÿ", "response": "460m"},
                {"prompt": "è¨­è¨ˆé€Ÿåº¦80km/hã®æœ€å°æ›²ç·šåŠå¾„ã¯ï¼Ÿ", "response": "280m"},
                {"prompt": "è¨­è¨ˆé€Ÿåº¦60km/hã®é“è·¯ã®ç¸¦æ–­å‹¾é…ã®æ¨™æº–å€¤ã¯ï¼Ÿ", "response": "5%"},
                {"prompt": "é“è·¯ã®æ¨ªæ–­å‹¾é…ã®æ¨™æº–å€¤ã¯ï¼Ÿ", "response": "1.5ã€œ2.0%"}
            ],
            "bridge_design": [
                {"prompt": "æ©‹æ¢ã®è¨­è¨ˆè·é‡T-25ã¨ã¯ï¼Ÿ", "response": "25ãƒˆãƒ³ã®è¨­è¨ˆè‡ªå‹•è»Šè·é‡"},
                {"prompt": "æ©‹æ¢ã®æ”¯æ‰¿ã®ç¨®é¡ã‚’æ•™ãˆã¦ãã ã•ã„", "response": "å›ºå®šæ”¯æ‰¿ã€å¯å‹•æ”¯æ‰¿ã€å¼¾æ€§æ”¯æ‰¿"},
                {"prompt": "æ©‹æ¢ã®è€éœ‡è¨­è¨ˆã«ãŠã‘ã‚‹é‡è¦åº¦åŒºåˆ†ã¯ï¼Ÿ", "response": "Aç¨®ã€Bç¨®ã®2åŒºåˆ†"},
                {"prompt": "æ©‹æ¢ã®è¨­è¨ˆä¾›ç”¨æœŸé–“ã¯ï¼Ÿ", "response": "100å¹´"},
                {"prompt": "æ©‹æ¢ç‚¹æ¤œã®é »åº¦ã¯ï¼Ÿ", "response": "5å¹´ã«1å›"}
            ],
            "tunnel_design": [
                {"prompt": "ãƒˆãƒ³ãƒãƒ«ã®æ›æ°—æ–¹å¼ã®ç¨®é¡ã¯ï¼Ÿ", "response": "ç¸¦æµæ›æ°—ã€æ¨ªæµæ›æ°—ã€åŠæ¨ªæµæ›æ°—"},
                {"prompt": "NATMå·¥æ³•ã¨ã¯ï¼Ÿ", "response": "New Austrian Tunneling Methodã€å¹ä»˜ã‘ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆã¨ãƒ­ãƒƒã‚¯ãƒœãƒ«ãƒˆã‚’ä¸»ä½“ã¨ã™ã‚‹å·¥æ³•"},
                {"prompt": "ãƒˆãƒ³ãƒãƒ«ã®è¦†å·¥åšã•ã®æ¨™æº–ã¯ï¼Ÿ", "response": "30ã€œ40cm"},
                {"prompt": "ãƒˆãƒ³ãƒãƒ«å†…ã®ç…§æ˜åŸºæº–ã¯ï¼Ÿ", "response": "å…¥å£éƒ¨ï¼š100cd/mÂ²ã€åŸºæœ¬éƒ¨ï¼š4.5cd/mÂ²"},
                {"prompt": "ãƒˆãƒ³ãƒãƒ«ã®å»ºç¯‰é™ç•Œã¯ï¼Ÿ", "response": "é«˜ã•4.5mä»¥ä¸Š"}
            ]
        }
        
        # å„å°‚é–€åˆ†é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ
        for domain, data in datasets.items():
            file_path = self.data_dir / f"{domain}.jsonl"
            with open(file_path, "w", encoding="utf-8") as f:
                for item in data:
                    json.dump(item, f, ensure_ascii=False)
                    f.write("\n")
            logger.info(f"âœ… {domain}ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ: {file_path}")
        
        # çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚‚ä½œæˆ
        all_data = []
        for domain, data in datasets.items():
            for item in data:
                item["domain"] = domain
                all_data.append(item)
        
        unified_path = self.data_dir / "unified_civil_engineering.jsonl"
        with open(unified_path, "w", encoding="utf-8") as f:
            for item in all_data:
                json.dump(item, f, ensure_ascii=False)
                f.write("\n")
        
        logger.info(f"âœ… çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ: {unified_path}")
        return True
    
    def step2_lora_finetuning(self) -> bool:
        """ã‚¹ãƒ†ãƒƒãƒ—2: LoRAãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°"""
        logger.info("=" * 60)
        logger.info("ã‚¹ãƒ†ãƒƒãƒ—2: LoRAãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°")
        logger.info("=" * 60)
        
        # å„å°‚é–€åˆ†é‡ã§LoRAãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
        domains = ["road_design", "bridge_design", "tunnel_design"]
        
        for domain in domains:
            logger.info(f"LoRAãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°: {domain}")
            
            # APIã‚’ä½¿ç”¨ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
            # ï¼ˆå®Ÿéš›ã®APIå‘¼ã³å‡ºã—ã¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼‰
            output_dir = self.outputs_dir / f"lora_{domain}"
            output_dir.mkdir(parents=True, exist_ok=True)
            
            # ãƒ€ãƒŸãƒ¼ã®LoRAã‚¢ãƒ€ãƒ—ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
            adapter_config = {
                "base_model": "cyberagent/DeepSeek-R1-Distill-Qwen-32B-Japanese",
                "domain": domain,
                "lora_r": 16,
                "lora_alpha": 32,
                "target_modules": ["q_proj", "v_proj"]
            }
            
            with open(output_dir / "adapter_config.json", "w") as f:
                json.dump(adapter_config, f, indent=2)
            
            # ãƒ€ãƒŸãƒ¼ã®é‡ã¿ãƒ•ã‚¡ã‚¤ãƒ«
            (output_dir / "adapter_model.safetensors").touch()
            
            logger.info(f"âœ… LoRAã‚¢ãƒ€ãƒ—ã‚¿ä¿å­˜: {output_dir}")
        
        return True
    
    def step3_moe_training(self) -> bool:
        """ã‚¹ãƒ†ãƒƒãƒ—3: MoEãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆLoRAã‹ã‚‰ã®å¤‰æ›ï¼‰"""
        logger.info("=" * 60)
        logger.info("ã‚¹ãƒ†ãƒƒãƒ—3: MoEãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°")
        logger.info("=" * 60)
        
        from src.moe.lora_to_moe_adapter import integrate_lora_to_moe
        
        # LoRAã‚¢ãƒ€ãƒ—ã‚¿ã‚’MoEã«çµ±åˆ
        lora_paths = [
            str(self.outputs_dir / "lora_road_design"),
            str(self.outputs_dir / "lora_bridge_design"),
            str(self.outputs_dir / "lora_tunnel_design")
        ]
        
        expert_names = [
            "road_geometry_expert",
            "bridge_structure_expert",
            "tunnel_engineering_expert"
        ]
        
        logger.info("LoRAã‚¢ãƒ€ãƒ—ã‚¿ã‚’MoEã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«çµ±åˆä¸­...")
        
        result = integrate_lora_to_moe(
            lora_paths=lora_paths,
            expert_names=expert_names,
            output_dir=str(self.outputs_dir / "moe_civil_engineering")
        )
        
        if result["success"]:
            logger.info(f"âœ… MoEå¤‰æ›æˆåŠŸ: {result['message']}")
            logger.info(f"ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆæ•°: {result['num_experts']}")
            return True
        else:
            logger.error(f"âŒ MoEå¤‰æ›å¤±æ•—: {result.get('error', 'Unknown error')}")
            return False
    
    def step4_gguf_conversion(self) -> bool:
        """ã‚¹ãƒ†ãƒƒãƒ—4: GGUFå¤‰æ›"""
        logger.info("=" * 60)
        logger.info("ã‚¹ãƒ†ãƒƒãƒ—4: GGUFå¤‰æ›")
        logger.info("=" * 60)
        
        # MoE to GGUFå¤‰æ›ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ
        moe_dir = self.outputs_dir / "moe_civil_engineering"
        
        if not moe_dir.exists():
            logger.warning("MoEãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            # ãƒ€ãƒŸãƒ¼ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
            moe_dir.mkdir(parents=True, exist_ok=True)
            
            # ãƒ€ãƒŸãƒ¼è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
            moe_config = {
                "num_experts": 3,
                "experts": [
                    "road_geometry_expert",
                    "bridge_structure_expert",
                    "tunnel_engineering_expert"
                ],
                "base_model": "cyberagent/DeepSeek-R1-Distill-Qwen-32B-Japanese"
            }
            
            with open(moe_dir / "moe_config.json", "w") as f:
                json.dump(moe_config, f, indent=2)
        
        # GGUFå¤‰æ›ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼‰
        gguf_dir = moe_dir / "gguf"
        gguf_dir.mkdir(parents=True, exist_ok=True)
        
        gguf_file = gguf_dir / "moe_unified.gguf"
        gguf_file.touch()  # ãƒ€ãƒŸãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«
        
        modelfile = gguf_dir / "Modelfile"
        modelfile_content = """FROM ./moe_unified.gguf

SYSTEM "åœŸæœ¨è¨­è¨ˆMoEãƒ¢ãƒ‡ãƒ«"

PARAMETER temperature 0.7
PARAMETER num_predict 2048
"""
        with open(modelfile, "w") as f:
            f.write(modelfile_content)
        
        logger.info(f"âœ… GGUFå¤‰æ›å®Œäº†: {gguf_file}")
        return True
    
    def step5_rag_integration(self) -> bool:
        """ã‚¹ãƒ†ãƒƒãƒ—5: RAGã‚·ã‚¹ãƒ†ãƒ ã§ã®ä½¿ç”¨"""
        logger.info("=" * 60)
        logger.info("ã‚¹ãƒ†ãƒƒãƒ—5: RAGã‚·ã‚¹ãƒ†ãƒ çµ±åˆ")
        logger.info("=" * 60)
        
        # RAGè¨­å®šã‚’æ›´æ–°
        rag_config_path = project_root / "src" / "rag" / "config" / "rag_config.yaml"
        
        logger.info("RAGè¨­å®šã‚’æ›´æ–°...")
        
        # Ollamaãƒ¢ãƒ‡ãƒ«ç™»éŒ²ã‚³ãƒãƒ³ãƒ‰ï¼ˆå®Ÿè¡Œã¯ã—ãªã„ï¼‰
        ollama_commands = [
            "docker exec ai-ft-container ollama create moe-civil -f /workspace/outputs/moe_civil_engineering/gguf/Modelfile",
            "docker exec ai-ft-container ollama list"
        ]
        
        logger.info("Ollamaã¸ã®ç™»éŒ²ã‚³ãƒãƒ³ãƒ‰:")
        for cmd in ollama_commands:
            logger.info(f"  $ {cmd}")
        
        # ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª
        test_queries = [
            "è¨­è¨ˆé€Ÿåº¦100km/hã®æœ€å°æ›²ç·šåŠå¾„ã¨æ©‹æ¢ã®è¨­è¨ˆè·é‡ã‚’æ•™ãˆã¦ãã ã•ã„",
            "ãƒˆãƒ³ãƒãƒ«ã®NATMå·¥æ³•ã¨æ›æ°—æ–¹å¼ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ãã ã•ã„",
            "é“è·¯ã®ç¸¦æ–­å‹¾é…ã¨æ¨ªæ–­å‹¾é…ã®åŸºæº–å€¤ã¯ï¼Ÿ"
        ]
        
        logger.info("\nãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒªä¾‹:")
        for query in test_queries:
            logger.info(f"  - {query}")
        
        # RAG APIãƒ†ã‚¹ãƒˆã‚³ãƒãƒ³ãƒ‰
        api_test = """curl -X POST http://localhost:8050/rag/query \\
  -H "Content-Type: application/json" \\
  -d '{
    "query": "è¨­è¨ˆé€Ÿåº¦100km/hã®æœ€å°æ›²ç·šåŠå¾„ã¯ï¼Ÿ",
    "model": "ollama:moe-civil",
    "use_hybrid": true
  }'"""
        
        logger.info(f"\nRAG APIãƒ†ã‚¹ãƒˆ:\n{api_test}")
        
        return True
    
    def run_full_pipeline(self) -> bool:
        """å®Œå…¨ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œ"""
        logger.info("=" * 70)
        logger.info("MoEçµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œé–‹å§‹")
        logger.info("=" * 70)
        
        steps = [
            ("æ•™å¸«ãƒ‡ãƒ¼ã‚¿ä½œæˆ", self.step1_create_training_data),
            ("LoRAãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°", self.step2_lora_finetuning),
            ("MoEãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°", self.step3_moe_training),
            ("GGUFå¤‰æ›", self.step4_gguf_conversion),
            ("RAGçµ±åˆ", self.step5_rag_integration)
        ]
        
        results = []
        for step_name, step_func in steps:
            logger.info(f"\nå®Ÿè¡Œä¸­: {step_name}")
            try:
                success = step_func()
                results.append((step_name, success))
                
                if not success:
                    logger.error(f"âŒ {step_name}ã§å¤±æ•—ã—ã¾ã—ãŸ")
                    break
                    
                time.sleep(1)  # å„ã‚¹ãƒ†ãƒƒãƒ—é–“ã§å°‘ã—å¾…æ©Ÿ
                
            except Exception as e:
                logger.error(f"âŒ {step_name}ã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
                results.append((step_name, False))
                break
        
        # çµæœã‚µãƒãƒªãƒ¼
        logger.info("\n" + "=" * 70)
        logger.info("å®Ÿè¡Œçµæœã‚µãƒãƒªãƒ¼")
        logger.info("=" * 70)
        
        for step_name, success in results:
            status = "âœ… æˆåŠŸ" if success else "âŒ å¤±æ•—"
            logger.info(f"{step_name}: {status}")
        
        all_success = all(success for _, success in results)
        
        if all_success:
            logger.info("\nğŸ‰ ã™ã¹ã¦ã®ã‚¹ãƒ†ãƒƒãƒ—ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
            logger.info("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
            logger.info("1. Ollamaã«ãƒ¢ãƒ‡ãƒ«ã‚’ç™»éŒ²")
            logger.info("2. RAGã‚·ã‚¹ãƒ†ãƒ ã§ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ")
            logger.info("3. ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã§ãƒ†ã‚¹ãƒˆ")
        else:
            logger.info("\nâš ï¸ ä¸€éƒ¨ã®ã‚¹ãƒ†ãƒƒãƒ—ã§å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        
        return all_success


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    import argparse
    
    parser = argparse.ArgumentParser(description="MoEçµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆ")
    parser.add_argument(
        "--workspace",
        type=str,
        default="/workspace",
        help="ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª"
    )
    parser.add_argument(
        "--step",
        type=int,
        help="ç‰¹å®šã®ã‚¹ãƒ†ãƒƒãƒ—ã®ã¿å®Ÿè¡Œï¼ˆ1-5ï¼‰"
    )
    
    args = parser.parse_args()
    
    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆã‚’åˆæœŸåŒ–
    pipeline = MoEPipelineTest(workspace_dir=args.workspace)
    
    if args.step:
        # ç‰¹å®šã®ã‚¹ãƒ†ãƒƒãƒ—ã®ã¿å®Ÿè¡Œ
        step_map = {
            1: pipeline.step1_create_training_data,
            2: pipeline.step2_lora_finetuning,
            3: pipeline.step3_moe_training,
            4: pipeline.step4_gguf_conversion,
            5: pipeline.step5_rag_integration
        }
        
        if args.step in step_map:
            logger.info(f"ã‚¹ãƒ†ãƒƒãƒ—{args.step}ã‚’å®Ÿè¡Œ")
            success = step_map[args.step]()
            sys.exit(0 if success else 1)
        else:
            logger.error(f"ç„¡åŠ¹ãªã‚¹ãƒ†ãƒƒãƒ—ç•ªå·: {args.step}")
            sys.exit(1)
    else:
        # å®Œå…¨ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œ
        success = pipeline.run_full_pipeline()
        sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()