#!/usr/bin/env python3
"""
RAGã‚·ã‚¹ãƒ†ãƒ ã®ãƒ¢ãƒ‡ãƒ«é¸æŠæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import requests
import json
import time
from pathlib import Path
import sys
import subprocess

# APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
BASE_URL = "http://localhost:8050"
RAG_API = f"{BASE_URL}/rag"

def check_ollama_models():
    """Ollamaã§åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’ç¢ºèª"""
    print("=" * 60)
    print("ğŸ“‹ Ollamaãƒ¢ãƒ‡ãƒ«ç¢ºèª")
    print("=" * 60)
    
    try:
        # Ollamaãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—
        result = subprocess.run(
            ["ollama", "list"],
            capture_output=True,
            text=True,
            timeout=10
        )
        
        if result.returncode == 0:
            print("âœ… åˆ©ç”¨å¯èƒ½ãªOllamaãƒ¢ãƒ‡ãƒ«:")
            print(result.stdout)
        else:
            print("âŒ Ollamaãƒ¢ãƒ‡ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼")
            print(result.stderr)
            
    except Exception as e:
        print(f"âŒ Ollamaç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
    
    print()

def test_model_update(model_name):
    """æŒ‡å®šã—ãŸãƒ¢ãƒ‡ãƒ«ã«è¨­å®šã‚’æ›´æ–°"""
    print(f"ğŸ”„ ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’æ›´æ–°ä¸­: {model_name}")
    
    settings = {
        "llm_model": model_name,
        "embedding_model": "intfloat/multilingual-e5-large",
        "temperature": 0.6
    }
    
    try:
        response = requests.post(
            f"{RAG_API}/update-settings",
            json=settings,
            timeout=10
        )
        
        if response.status_code == 200:
            data = response.json()
            if data.get("status") == "success":
                print(f"âœ… ãƒ¢ãƒ‡ãƒ«è¨­å®šæ›´æ–°æˆåŠŸ: {model_name}")
                return True
            else:
                print(f"âŒ è¨­å®šæ›´æ–°å¤±æ•—: {data.get('message')}")
        else:
            print(f"âŒ HTTP Error {response.status_code}: {response.text}")
            
    except Exception as e:
        print(f"âŒ è¨­å®šæ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
    
    return False

def test_rag_query(query, model_name=None):
    """RAGã‚¯ã‚¨ãƒªãƒ†ã‚¹ãƒˆ"""
    print(f"\nğŸ“ ã‚¯ã‚¨ãƒªãƒ†ã‚¹ãƒˆ: '{query}'")
    if model_name:
        print(f"   ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_name}")
    
    request_data = {
        "query": query,
        "top_k": 3,
        "search_type": "hybrid",
        "include_sources": True
    }
    
    try:
        response = requests.post(
            f"{RAG_API}/query",
            json=request_data,
            timeout=30
        )
        
        if response.status_code == 200:
            data = response.json()
            print(f"âœ… ã‚¯ã‚¨ãƒªæˆåŠŸ")
            print(f"   å›ç­”æ–‡å­—æ•°: {len(data.get('answer', ''))}")
            
            # ä½¿ç”¨ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ç¢ºèªï¼ˆãƒ­ã‚°ã‹ã‚‰æ¨æ¸¬ï¼‰
            answer = data.get('answer', '')
            if 'DeepSeek' in answer or 'deepseek' in answer.lower():
                print("   æ¨å®šä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: DeepSeek-32B")
            elif 'Llama' in answer or 'llama' in answer.lower():
                print("   æ¨å®šä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: Llama 3.2")
            
            # å›ç­”ã®æœ€åˆã®200æ–‡å­—ã‚’è¡¨ç¤º
            print(f"   å›ç­”å†’é ­: {answer[:200]}...")
            return True
            
        else:
            print(f"âŒ HTTP Error {response.status_code}")
            print(f"   è©³ç´°: {response.text[:500]}")
            
    except Exception as e:
        print(f"âŒ ã‚¯ã‚¨ãƒªã‚¨ãƒ©ãƒ¼: {e}")
    
    return False

def get_current_config():
    """ç¾åœ¨ã®è¨­å®šã‚’å–å¾—"""
    print("\nğŸ“Š ç¾åœ¨ã®RAGè¨­å®šç¢ºèª")
    
    try:
        response = requests.get(
            f"{RAG_API}/system-info",
            timeout=10
        )
        
        if response.status_code == 200:
            data = response.json()
            config = data.get('system_info', {}).get('config', {})
            llm_config = config.get('llm', {})
            
            print(f"âœ… ç¾åœ¨ã®è¨­å®š:")
            print(f"   Provider: {llm_config.get('provider', 'ä¸æ˜')}")
            print(f"   Model Name: {llm_config.get('model_name', 'ä¸æ˜')}")
            print(f"   Ollama Model: {llm_config.get('ollama_model', 'ä¸æ˜')}")
            print(f"   Temperature: {llm_config.get('temperature', 'ä¸æ˜')}")
            
            if llm_config.get('ollama'):
                print(f"   Ollama Config:")
                print(f"     - Model: {llm_config['ollama'].get('model', 'ä¸æ˜')}")
                print(f"     - Base URL: {llm_config['ollama'].get('base_url', 'ä¸æ˜')}")
            
            return llm_config
        else:
            print(f"âŒ è¨­å®šå–å¾—å¤±æ•—: HTTP {response.status_code}")
            
    except Exception as e:
        print(f"âŒ è¨­å®šå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
    
    return None

def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("ğŸš€ RAGãƒ¢ãƒ‡ãƒ«é¸æŠæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 60)
    
    # 1. Ollamaãƒ¢ãƒ‡ãƒ«ç¢ºèª
    check_ollama_models()
    
    # 2. ç¾åœ¨ã®è¨­å®šç¢ºèª
    current_config = get_current_config()
    
    # 3. ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª
    test_query = "é“è·¯ã®è¨­è¨ˆé€Ÿåº¦80km/hã®å ´åˆã®æœ€å°æ›²ç·šåŠå¾„ã¯ï¼Ÿ"
    
    print("\n" + "=" * 60)
    print("ğŸ“ ãƒ¢ãƒ‡ãƒ«åˆ‡ã‚Šæ›¿ãˆãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    # 4. Llama 3.2ã§ãƒ†ã‚¹ãƒˆ
    print("\n--- Test 1: Llama 3.2 3B ---")
    if test_model_update("ollama:llama3.2:3b"):
        time.sleep(2)  # è¨­å®šåæ˜ å¾…ã¡
        test_rag_query(test_query, "llama3.2:3b")
    
    # 5. DeepSeek-32Bã§ãƒ†ã‚¹ãƒˆ
    print("\n--- Test 2: DeepSeek-32B Finetuned ---")
    if test_model_update("ollama:deepseek-32b-finetuned"):
        time.sleep(2)  # è¨­å®šåæ˜ å¾…ã¡
        test_rag_query(test_query, "deepseek-32b-finetuned")
    
    # 6. æœ€çµ‚è¨­å®šç¢ºèª
    print("\n" + "=" * 60)
    print("ğŸ“Š ãƒ†ã‚¹ãƒˆå¾Œã®è¨­å®šç¢ºèª")
    print("=" * 60)
    get_current_config()
    
    print("\n" + "=" * 60)
    print("âœ… ãƒ†ã‚¹ãƒˆå®Œäº†")
    print("=" * 60)
    print("\nğŸ’¡ Web UIã§ã®ç¢ºèªæ–¹æ³•:")
    print("1. http://localhost:8050/rag ã«ã‚¢ã‚¯ã‚»ã‚¹")
    print("2. 'RAGã‚·ã‚¹ãƒ†ãƒ è¨­å®š'ã‚¿ãƒ–ã‚’é–‹ã")
    print("3. 'LLMï¼ˆå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰é¸æŠ'ãƒ—ãƒ«ãƒ€ã‚¦ãƒ³ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ")
    print("4. 'è¨­å®šã‚’ä¿å­˜'ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯")
    print("5. 'ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ãƒ»è³ªå•å¿œç­”'ã‚¿ãƒ–ã§è³ªå•ã‚’å®Ÿè¡Œ")

if __name__ == "__main__":
    main()