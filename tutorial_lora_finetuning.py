#!/usr/bin/env python3
"""
å®Ÿè·µçš„LoRAãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«
RTX A5000 x2ç’°å¢ƒæœ€é©åŒ–æ¸ˆã¿
"""

import torch
import os
from datetime import datetime
from src.models.japanese_model import JapaneseModel
from src.training.lora_finetuning import LoRAFinetuningTrainer, LoRAConfig
from src.training.training_utils import TrainingConfig

def main():
    print("ğŸš€ RTX A5000 x2 LoRAãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè·µã‚¬ã‚¤ãƒ‰")
    print("=" * 60)
    
    # GPUç¢ºèª
    if torch.cuda.device_count() >= 2:
        print(f"âœ… {torch.cuda.device_count()}å°ã®GPUæ¤œå‡º")
        for i in range(torch.cuda.device_count()):
            props = torch.cuda.get_device_properties(i)
            print(f"   GPU {i}: {props.name} ({props.total_memory/(1024**3):.1f}GB)")
    
    # Step 1: ãƒ¢ãƒ‡ãƒ«é¸æŠ
    print("\nğŸ“š Step 1: ãƒ¢ãƒ‡ãƒ«é¸æŠ")
    print("æ¨å¥¨ãƒ¢ãƒ‡ãƒ«ï¼ˆRTX A5000 x2ç’°å¢ƒï¼‰:")
    print("â€¢ stabilityai/japanese-stablelm-3b-4e1t-instruct (8GBä½¿ç”¨)")
    print("â€¢ elyza/Llama-3-ELYZA-JP-8B (16GBä½¿ç”¨)")
    
    # è»½é‡ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰é–‹å§‹
    model_name = "stabilityai/japanese-stablelm-3b-4e1t-instruct"
    print(f"\né¸æŠ: {model_name}")
    
    # Step 2: ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
    print("\nğŸ”§ Step 2: ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–")
    model = JapaneseModel(
        model_name=model_name,
        load_in_8bit=True,  # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–
        use_flash_attention=True,  # é«˜é€ŸåŒ–
        gradient_checkpointing=True  # ãƒ¡ãƒ¢ãƒªç¯€ç´„
    )
    
    print("âœ… ãƒ¢ãƒ‡ãƒ«è¨­å®šå®Œäº†")
    
    # Step 3: è¨“ç·´ãƒ‡ãƒ¼ã‚¿æº–å‚™
    print("\nğŸ“ Step 3: è¨“ç·´ãƒ‡ãƒ¼ã‚¿æº–å‚™")
    
    # å®Ÿç”¨çš„ãªä¾‹ï¼šQ&Aã‚·ã‚¹ãƒ†ãƒ 
    train_texts = [
        "è³ªå•: æ±äº¬ã®äººå£ã¯ä½•äººã§ã™ã‹ï¼Ÿ\nå›ç­”: æ±äº¬éƒ½ã®äººå£ã¯ç´„1,400ä¸‡äººã§ã™ã€‚",
        "è³ªå•: æ—¥æœ¬ã§ä¸€ç•ªé«˜ã„å±±ã¯ã©ã“ã§ã™ã‹ï¼Ÿ\nå›ç­”: æ—¥æœ¬ã§ä¸€ç•ªé«˜ã„å±±ã¯å¯Œå£«å±±ã§ã€æ¨™é«˜3,776ãƒ¡ãƒ¼ãƒˆãƒ«ã§ã™ã€‚",
        "è³ªå•: æ—¥æœ¬ã®é¦–éƒ½ã¯ã©ã“ã§ã™ã‹ï¼Ÿ\nå›ç­”: æ—¥æœ¬ã®é¦–éƒ½ã¯æ±äº¬ã§ã™ã€‚",
        "è³ªå•: æ—¥æœ¬èªã§ã“ã‚“ã«ã¡ã¯ã¯ä½•ã¨è¨€ã„ã¾ã™ã‹ï¼Ÿ\nå›ç­”: æ—¥æœ¬èªã§æŒ¨æ‹¶ã™ã‚‹æ™‚ã¯ã€Œã“ã‚“ã«ã¡ã¯ã€ã¨è¨€ã„ã¾ã™ã€‚",
        "è³ªå•: å¯¿å¸ã®ä¸»ãªææ–™ã¯ä½•ã§ã™ã‹ï¼Ÿ\nå›ç­”: å¯¿å¸ã®ä¸»ãªææ–™ã¯é…¢é£¯ã¨æ–°é®®ãªé­šä»‹é¡ã§ã™ã€‚",
        "è³ªå•: æ¡œã®å­£ç¯€ã¯ã„ã¤ã§ã™ã‹ï¼Ÿ\nå›ç­”: æ¡œã®å­£ç¯€ã¯é€šå¸¸3æœˆä¸‹æ—¬ã‹ã‚‰5æœˆä¸Šæ—¬ã§ã™ã€‚",
        "è³ªå•: æ—¥æœ¬ã®é€šè²¨ã¯ä½•ã§ã™ã‹ï¼Ÿ\nå›ç­”: æ—¥æœ¬ã®é€šè²¨ã¯å††ï¼ˆãˆã‚“ï¼‰ã§ã™ã€‚",
        "è³ªå•: æ–°å¹¹ç·šã®æœ€é«˜é€Ÿåº¦ã¯ã©ã®ãã‚‰ã„ã§ã™ã‹ï¼Ÿ\nå›ç­”: æ–°å¹¹ç·šã®æœ€é«˜é€Ÿåº¦ã¯è·¯ç·šã«ã‚ˆã‚Šç•°ãªã‚Šã¾ã™ãŒã€æœ€é«˜320km/hã§ã™ã€‚",
        "è³ªå•: æ—¥æœ¬ã®å›½èŠ±ã¯ä½•ã§ã™ã‹ï¼Ÿ\nå›ç­”: æ—¥æœ¬ã®å›½èŠ±ã¯æ¡œã§ã™ã€‚",
        "è³ªå•: å‘³å™Œæ±ã®ä¸»ãªææ–™ã¯ä½•ã§ã™ã‹ï¼Ÿ\nå›ç­”: å‘³å™Œæ±ã®ä¸»ãªææ–™ã¯å‘³å™Œã€ã ã—ã€å…·æï¼ˆè±†è…ã€ã‚ã‹ã‚ãªã©ï¼‰ã§ã™ã€‚"
    ]
    
    print(f"âœ… è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(train_texts)}ä»¶")
    
    # Step 4: LoRAè¨­å®š
    print("\nâš™ï¸ Step 4: LoRAè¨­å®šï¼ˆRTX A5000 x2æœ€é©åŒ–ï¼‰")
    
    lora_config = LoRAConfig(
        r=16,  # LoRAãƒ©ãƒ³ã‚¯ï¼ˆå“è³ªã¨é€Ÿåº¦ã®ãƒãƒ©ãƒ³ã‚¹ï¼‰
        lora_alpha=32,  # ã‚¢ãƒ«ãƒ•ã‚¡å€¤ï¼ˆé€šå¸¸r*2ï¼‰
        target_modules=["q_proj", "v_proj", "k_proj", "o_proj"],  # å¯¾è±¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
        lora_dropout=0.05,  # ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆ
        use_qlora=False,  # QLoRAã¯ä½¿ç”¨ã—ãªã„ï¼ˆ8bité‡å­åŒ–ã§ååˆ†ï¼‰
        bias="none"
    )
    
    print("âœ… LoRAè¨­å®š:")
    print(f"   ãƒ©ãƒ³ã‚¯: {lora_config.r}")
    print(f"   ã‚¢ãƒ«ãƒ•ã‚¡: {lora_config.lora_alpha}")
    print(f"   å¯¾è±¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«: {lora_config.target_modules}")
    
    # Step 5: è¨“ç·´è¨­å®š
    print("\nğŸ“Š Step 5: è¨“ç·´è¨­å®š")
    
    output_dir = f"./outputs/lora_qa_system_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    training_config = TrainingConfig(
        learning_rate=3e-4,  # LoRAæ¨å¥¨å­¦ç¿’ç‡
        batch_size=4,  # RTX A5000ã§å®‰å…¨ãªã‚µã‚¤ã‚º
        gradient_accumulation_steps=4,  # å®ŸåŠ¹ãƒãƒƒãƒã‚µã‚¤ã‚º16
        num_epochs=5,  # å°‘ãªã„ãƒ‡ãƒ¼ã‚¿ãªã®ã§å¤šã‚ã®ã‚¨ãƒãƒƒã‚¯
        warmup_steps=50,
        max_grad_norm=1.0,
        eval_steps=10,
        save_steps=50,
        logging_steps=5,
        output_dir=output_dir,
        fp16=True,  # RTX A5000ã§é«˜é€ŸåŒ–
        gradient_checkpointing=True,  # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–
        ddp=False  # å˜ä¸€ãƒ—ãƒ­ã‚»ã‚¹ã‹ã‚‰é–‹å§‹
    )
    
    print("âœ… è¨“ç·´è¨­å®š:")
    print(f"   å­¦ç¿’ç‡: {training_config.learning_rate}")
    print(f"   ãƒãƒƒãƒã‚µã‚¤ã‚º: {training_config.batch_size}")
    print(f"   å®ŸåŠ¹ãƒãƒƒãƒã‚µã‚¤ã‚º: {training_config.batch_size * training_config.gradient_accumulation_steps}")
    print(f"   ã‚¨ãƒãƒƒã‚¯æ•°: {training_config.num_epochs}")
    print(f"   å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}")
    
    # Step 6: è¨“ç·´å®Ÿè¡Œ
    print("\nğŸ‹ï¸ Step 6: è¨“ç·´å®Ÿè¡Œ")
    
    try:
        trainer = LoRAFinetuningTrainer(
            model=model,
            lora_config=lora_config,
            training_config=training_config
        )
        
        print("âœ… ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼åˆæœŸåŒ–å®Œäº†")
        print("ğŸš€ è¨“ç·´é–‹å§‹...")
        
        # è¨“ç·´å‰ã®ãƒ†ã‚¹ãƒˆ
        print("\n--- è¨“ç·´å‰ã®ãƒ†ã‚¹ãƒˆ ---")
        test_input = "è³ªå•: æ—¥æœ¬ã®é¦–éƒ½ã¯ã©ã“ã§ã™ã‹ï¼Ÿ"
        
        if hasattr(trainer, 'model') and trainer.model.model is not None:
            response = model.generate_japanese(test_input, max_new_tokens=50)
            print(f"å…¥åŠ›: {test_input}")
            print(f"å‡ºåŠ›: {response}")
        
        # å®Ÿéš›ã®è¨“ç·´
        trained_model = trainer.train(train_texts=train_texts)
        
        print("\nâœ… è¨“ç·´å®Œäº†ï¼")
        
        # è¨“ç·´å¾Œã®ãƒ†ã‚¹ãƒˆ
        print("\n--- è¨“ç·´å¾Œã®ãƒ†ã‚¹ãƒˆ ---")
        if trained_model:
            response = model.generate_japanese(test_input, max_new_tokens=50)
            print(f"å…¥åŠ›: {test_input}")
            print(f"å‡ºåŠ›: {response}")
        
        print(f"\nğŸ’¾ ãƒ¢ãƒ‡ãƒ«ä¿å­˜å ´æ‰€: {output_dir}")
        print("âœ… LoRAãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†ï¼")
        
        return True
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        return False

def usage_tips():
    """ä½¿ç”¨ã®ãƒ’ãƒ³ãƒˆ"""
    print("\nğŸ’¡ ä½¿ç”¨ã®ãƒ’ãƒ³ãƒˆ:")
    print("=" * 30)
    print("1. åˆå›ã¯è»½é‡ãƒ¢ãƒ‡ãƒ«ï¼ˆ3Bï¼‰ã‹ã‚‰é–‹å§‹")
    print("2. ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã„å ´åˆã¯ã‚¨ãƒãƒƒã‚¯æ•°ã‚’å¢—ã‚„ã™")
    print("3. ãƒ¡ãƒ¢ãƒªä¸è¶³ã®å ´åˆã¯batch_sizeã‚’ä¸‹ã’ã‚‹")
    print("4. å­¦ç¿’ç‡ã¯3e-4ã‹ã‚‰å§‹ã‚ã¦èª¿æ•´")
    print("5. ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯å¾Œã§èª­ã¿è¾¼ã¿å¯èƒ½")
    
    print("\nğŸ”„ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("â€¢ ã‚ˆã‚Šå¤§ããªãƒ¢ãƒ‡ãƒ«ï¼ˆ8Bï¼‰ã‚’è©¦ã™")
    print("â€¢ QLoRAã§13B+ãƒ¢ãƒ‡ãƒ«ã«æŒ‘æˆ¦")
    print("â€¢ ç‹¬è‡ªãƒ‡ãƒ¼ã‚¿ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°")
    print("â€¢ ãƒãƒ«ãƒGPUè¨­å®šã§é«˜é€ŸåŒ–")

if __name__ == "__main__":
    try:
        success = main()
        if success:
            usage_tips()
    except KeyboardInterrupt:
        print("\nâš ï¸ è¨“ç·´ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")